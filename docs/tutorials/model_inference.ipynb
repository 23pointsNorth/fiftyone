{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Inference-in-the-Loop with FiftyOne\n",
    "\n",
    "This walkthrough provides a glimpse into the possibilities for integrating\n",
    "FiftyOne into your machine learning workflows. It covers the following\n",
    "concepts:\n",
    "\n",
    "-   Loading your existing dataset in FiftyOne\n",
    "-   Adding predictions from your model to your FiftyOne dataset\n",
    "-   Launching the FiftyOne dashboard and visualizing/exploring your data\n",
    "-   Integrating the dashboard into your data wrangling workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "-   Install `torch` and `torchvision`, if necessary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify as necessary (e.g., GPU install). See https://pytorch.org for options\n",
    "!pip install torch\n",
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Download the test split of the CIFAR-10 dataset to\n",
    "\n",
    "    `~/fiftyone/cifar10/test`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!fiftyone zoo download cifar10 --splits test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Download a pretrained CIFAR-10 PyTorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the software\n",
    "!git clone https://github.com/huyvnphan/PyTorch_CIFAR10\n",
    "\n",
    "# Download the pretrained model (90MB)\n",
    "!eta gdrive download --public \\\n",
    "    1dGfpeFK_QG0kV-U6QDHMX2EOGXPqaNzu \\\n",
    "    PyTorch_CIFAR10/cifar10_models/state_dicts/resnet50.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing FiftyOne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading an image classification dataset\n",
    "\n",
    "Suppose you have an image classification dataset on disk in the following\n",
    "format:\n",
    "\n",
    "```\n",
    "<dataset_dir>/\n",
    "    data/\n",
    "        <uuid1>.<ext>\n",
    "        <uuid2>.<ext>\n",
    "        ...\n",
    "    labels.json\n",
    "```\n",
    "\n",
    "where `labels.json` is a JSON file in the following format:\n",
    "\n",
    "```\n",
    "{\n",
    "    \"classes\": [\n",
    "        <labelA>,\n",
    "        <labelB>,\n",
    "        ...\n",
    "    ],\n",
    "    \"labels\": {\n",
    "        <uuid1>: <target1>,\n",
    "        <uuid2>: <target2>,\n",
    "        ...\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "In your current workflow, you may parse this data into a list of\n",
    "`(image_path, label)` tuples as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# The location of the dataset on disk that you downloaded above\n",
    "dataset_dir = os.path.expanduser(\"~/fiftyone/cifar10/test\")\n",
    "\n",
    "# Maps image UUIDs to image paths\n",
    "images_dir = os.path.join(dataset_dir, \"data\")\n",
    "image_uuids_to_paths = {\n",
    "    os.path.splitext(n)[0]: os.path.join(images_dir, n)\n",
    "    for n in os.listdir(images_dir)\n",
    "}\n",
    "\n",
    "labels_path = os.path.join(dataset_dir, \"labels.json\")\n",
    "with open(labels_path, \"rt\") as f:\n",
    "    _labels = json.load(f)\n",
    "\n",
    "# Get classes\n",
    "classes = _labels[\"classes\"]\n",
    "\n",
    "# Maps image UUIDs to int targets\n",
    "labels = _labels[\"labels\"]\n",
    "\n",
    "# Make a list of (image_path, label) samples\n",
    "samples = [(image_uuids_to_paths[u], classes[t]) for u, t in labels.items()]\n",
    "\n",
    "# Print a few samples\n",
    "print(samples[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a FiftyOne dataset from your samples is simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = fo.Dataset.from_image_classification_samples(\n",
    "    samples, name=\"my-dataset\"\n",
    ")\n",
    "\n",
    "# Print a few samples from the dataset\n",
    "print(dataset.view().head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with views into your dataset\n",
    "\n",
    "FiftyOne provides a powerful notion of _dataset views_ for you to access\n",
    "subsets of the samples in your dataset.\n",
    "\n",
    "Here's an example operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets five random airplanes from the dataset\n",
    "view = (dataset.view()\n",
    "    .match(filter={\"ground_truth.label\": \"airplane\"})\n",
    "    .take(5)\n",
    ")\n",
    "\n",
    "# Print some information about the entire dataset\n",
    "print(dataset)\n",
    "\n",
    "# Print some information about the view you created\n",
    "print(view)\n",
    "\n",
    "# Print a few samples from the view\n",
    "print(view.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterating over the samples in a view is easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in view:\n",
    "    print(sample.filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding model predictions to your dataset\n",
    "\n",
    "The following code demonstrates how to add predictions from a model to your\n",
    "FiftyOne dataset, with minimal changes to your existing ML code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import fiftyone.utils.torch as fout\n",
    "\n",
    "sys.path.insert(1, \"PyTorch_CIFAR10\")\n",
    "from cifar10_models import *\n",
    "\n",
    "\n",
    "def make_cifar10_data_loader(image_paths, sample_ids, batch_size):\n",
    "    mean = [0.4914, 0.4822, 0.4465]\n",
    "    std = [0.2023, 0.1994, 0.2010]\n",
    "    transforms = torchvision.transforms.Compose(\n",
    "        [\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize(mean, std),\n",
    "        ]\n",
    "    )\n",
    "    dataset = fout.TorchImageDataset(\n",
    "        image_paths, sample_ids=sample_ids, transform=transforms\n",
    "    )\n",
    "    return DataLoader(dataset, batch_size=batch_size, num_workers=4)\n",
    "\n",
    "\n",
    "def predict(model, imgs):\n",
    "    logits = model(imgs).detach().cpu().numpy()\n",
    "    predictions = np.argmax(logits, axis=1)\n",
    "    odds = np.exp(logits)\n",
    "    confidences = np.max(odds, axis=1) / np.sum(odds, axis=1)\n",
    "    return predictions, confidences\n",
    "\n",
    "\n",
    "#\n",
    "# Load a model\n",
    "#\n",
    "# Model performance numbers are available at:\n",
    "#   https://github.com/huyvnphan/PyTorch_CIFAR10\n",
    "#\n",
    "\n",
    "model = resnet50(pretrained=True)\n",
    "model_name = \"resnet50\"\n",
    "\n",
    "#\n",
    "# Extract a few images to process\n",
    "#\n",
    "\n",
    "num_samples = 25\n",
    "batch_size = 5\n",
    "view = dataset.view().take(num_samples)\n",
    "image_paths, sample_ids = zip(*[(s.filepath, s.id) for s in view])\n",
    "data_loader = make_cifar10_data_loader(image_paths, sample_ids, batch_size)\n",
    "\n",
    "#\n",
    "# Perform prediction and store results in dataset\n",
    "#\n",
    "\n",
    "for imgs, sample_ids in data_loader:\n",
    "    predictions, confidences = predict(model, imgs)\n",
    "\n",
    "    # Add predictions to your FiftyOne dataset\n",
    "    for sample_id, prediction, confidence in zip(\n",
    "        sample_ids, predictions, confidences\n",
    "    ):\n",
    "        sample = dataset[sample_id]\n",
    "        sample[model_name] = fo.Classification(\n",
    "            label=classes[prediction],\n",
    "            confidence=confidence,\n",
    "        )\n",
    "        sample.save()\n",
    "\n",
    "#\n",
    "# Get the last batch of samples for which we added predictions\n",
    "#\n",
    "\n",
    "view = dataset.view().select(sample_ids)\n",
    "print(view.head(batch_size))\n",
    "\n",
    "#\n",
    "# Get all samples for which we added predictions, in reverse order of\n",
    "# confidence\n",
    "#\n",
    "\n",
    "pred_view = (dataset.view()\n",
    "    .exists(model_name)\n",
    "    .sort_by(\"%s.confidence\" % model_name, reverse=True)\n",
    ")\n",
    "print(len(pred_view))\n",
    "print(pred_view.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the FiftyOne Dashboard\n",
    "\n",
    "FiftyOne provides a powerful dashboard that allows you easily visualize,\n",
    "explore, search, filter, your datasets.\n",
    "\n",
    "You can explore the dashboard interactively through the GUI, and you can even\n",
    "interact with it in real-time from your Python interpreter!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch the FiftyOne Dashboard\n",
    "session = fo.launch_dashboard()\n",
    "\n",
    "# Open your dataset in the dashboard\n",
    "session.dataset = dataset\n",
    "\n",
    "# Show five random samples in the dashboard\n",
    "view = dataset.view().limit(5)\n",
    "session.view = view\n",
    "\n",
    "# Show the samples for which we previously added pre\n",
    "session.view = pred_view\n",
    "\n",
    "# Show the full dataset again\n",
    "session.view = None\n",
    "\n",
    "# Print details about the selected samples\n",
    "selected_view = dataset.view().select(session.selected)\n",
    "print(selected_view)\n",
    "print(selected_view.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
