
.. _model-zoo:

FiftyOne Model Zoo
==================

.. default-role:: code

FiftyOne provides a Model Zoo that contains a collection of pre-trained models
that you can download and run inference on your FiftyOne Datasets via a few
simple commands.

You can interact with the Model Zoo either via the Python library or the CLI.

.. tabs::

  .. group-tab:: Python

    The Model Zoo is accessible via the :mod:`fiftyone.zoo.models` package.

  .. group-tab:: CLI

    The :ref:`fiftyone model-zoo <cli-fiftyone-model-zoo>` CLI command provides
    convenient utilities for working with models in the FiftyOne Model Zoo.

.. note::

    Zoo models may require additional packages such as TensorFlow or PyTorch
    (or specific versions of them) in order to be used. See
    :ref:`this section <model-zoo-requirements>` for more information on
    viewing/installing package requirements for models.

    If you try to load a zoo model without the proper packages installed, you
    will receive an error message that will explain what you need to install.

    Depending on your compute environment, some package requirement failures
    may be erroneous. In such cases, you can
    :ref:`suppress error messages <applying-zoo-models>`.

.. _model-zoo-basic-recipe:

Basic recipe
------------

Methods for working with the Model Zoo are conveniently exposed via the Python
library and the CLI. The basic recipe is that you load a model from the zoo and
then apply it to a dataset (or a subset of the dataset specified by a
|DatasetView|) using methods such as
:meth:`apply_model() <fiftyone.core.collections.SampleCollection.apply_model>`.

Prediction
~~~~~~~~~~

The Model Zoo provides a number of convenient methods for generating
predictions with zoo models for your datasets.

For example, the code sample below shows a self-contained example of loading a
Faster R-CNN PyTorch model from the model zoo and adding its predictions to the
COCO-2017 dataset from the :ref:`Dataset Zoo <dataset-zoo>`:

.. code-block:: python
    :linenos:

    import fiftyone as fo
    import fiftyone.zoo as foz
    import fiftyone.zoo.models as fozm

    # List available zoo models
    model_names = fozm.list_zoo_models()
    print(model_names)

    #
    # Load zoo model
    #
    # This will download the model from the web, if necessary, and ensure
    # that any required packages are installed
    #
    model = fozm.load_zoo_model("faster-rcnn-resnet50-fpn-coco-torch")

    #
    # Load some samples from the COCO-2017 validation split
    #
    # This will download the dataset from the web, if necessary
    #
    dataset = foz.load_zoo_dataset(
        "coco-2017",
        split="validation",
        dataset_name="coco-2017-example",
        max_samples=100,
        shuffle=True,
    )

    #
    # Choose some samples to process. This can be the entire dataset, or a
    # subset of the dataset. In this case, we'll choose some samples at
    # random
    #
    samples = dataset.take(25)

    #
    # Generate predictions for each sample and store the results in the
    # `faster_rcnn` field of the dataset, discarding all predictions with
    # confidence below 0.5
    #
    samples.apply_model(model, "faster_rcnn", confidence_thresh=0.5)
    print(samples)

    # Visualize predictions in the App
    session = fo.launch_app(view=samples)

Embeddings
~~~~~~~~~~

Many models in the Model Zoo expose embeddings for their predictions:

.. code-block:: python
    :linenos:

    import fiftyone.zoo.models as fozm

    # Load zoo model
    model = fozm.load_zoo_model("inception-v3-imagenet-torch")

    # Check if model exposes embeddings
    print(model.has_embeddings)  # True

For models that expose embeddings, you can generate embeddings for all
samples in a dataset (or a subset of it specified by a |DatasetView|) by
calling
:meth:`compute_embeddings() <fiftyone.core.collections.SampleCollection.compute_embeddings>`:

.. code-block:: python
    :linenos:

    import fiftyone.zoo as foz
    import fiftyone.zoo.models as fozm

    # Load zoo model
    model = fozm.load_zoo_model("inception-v3-imagenet-torch")
    print(model.has_embeddings)  # True

    # Load zoo dataset
    dataset = foz.load_zoo_dataset("quickstart")

    # Select some samples to process
    samples = dataset.take(10)

    #
    # Option 1: Generate embeddings for each sample and return them in a
    # `num_samples x dim` array
    #
    embeddings = samples.compute_embeddings(model)

    #
    # Option 2: Generate embeddings for each sample and store them in an
    # `embeddings` field of the dataset
    #
    samples.compute_embeddings(model, embeddings_field="embeddings")

You can also use
:meth:`compute_patch_embeddings() <fiftyone.core.collections.SampleCollection.compute_patch_embeddings>`
to generate embeddings for image patches defined by another label field, e.g,.
the detections generated by a detection model.

.. _model-zoo-design-overview:

Models Design Overview
----------------------

All models in the FiftyOne Model Zoo are instances of the |Model| class, which
defines a common interface for loading models and generating predictions with
defined input and output data formats.

.. note:

    The following sections describe the interface that all models in the Model
    Zoo implement. If you write a wrapper for your custom model that implements
    the |Model| interface, then you can pass your models to builtin methods
    like
    :meth:`apply_model() <fiftyone.core.collections.SampleCollection.apply_model>`
    and
    :meth:`compute_embeddings() <fiftyone.core.collections.SampleCollection.compute_embeddings>`
    too!

    FiftyOne provides classes that make it easy to deploy models in custom
    frameworks easy. For example, if you have a PyTorch model that processes
    images, you can likely use
    :class:`TorchImageModel <fiftyone.utils.torch.TorchImageModel>` to run it
    using FiftyOne.

Prediction
~~~~~~~~~~

Inside builtin methods like
:meth:`apply_model() <fiftyone.core.collections.SampleCollection.apply_model>`,
predictions of a |Model| instance are generated using the following pattern:

.. tabs::

  .. group-tab:: Image models

    .. code-block:: python
        :linenos:

        import numpy as np
        from PIL import Image

        import fiftyone as fo

        def read_rgb_image(path):
            """Utility function that loads an image as an RGB numpy aray."""
            return np.asarray(Image.open(path).convert("rgb"))

        # Load a `Model` instance that processes images
        model = ...

        # Load a FiftyOne dataset
        dataset = fo.load_dataset(...)

        # A sample field in which to store the predictions
        label_field = "predictions"

        # Perform prediction on all images in the dataset
        with model:
            for sample in dataset:
                # Load image
                img = read_rgb_image(sample.filepath)

                # Perform prediction
                labels = model.predict(img)

                # Save labels
                sample.add_labels(labels, label_field)

  .. group-tab:: Video models

    .. code-block:: python
        :linenos:

        import eta.core.video as etav

        import fiftyone as fo

        # Load a `Model` instance that processes videos
        model = ...

        # Load a FiftyOne dataset
        dataset = fo.load_dataset(...)

        # A sample field in which to store the predictions
        label_field = "predictions"

        # Perform prediction on all videos in the dataset
        with model:
            for sample in dataset:
                # Perform prediction
                with etav.FFmpegVideoReader(sample.filepath) as video_reader:
                    labels = model.predict(video_reader)

                # Save labels
                sample.add_labels(labels, label_field)

By convention, |Model| instances must implement the context manager interface,
which handles any necessary setup and teardown required to use the model.

Predictions are generated via the
:meth:`Model.predict() <fiftyone.core.models.Model>` interface method, which
takes an image/video as input and returns the predictions.

In order to be compatible with builtin methods like
:meth:`apply_model() <fiftyone.core.collections.SampleCollection.apply_model>`,
models should support the following basic signature of running inference and
storing the output labels:

.. code-block:: python
    :linenos:

    labels = model.predict(arg)
    sample.add_labels(labels, label_field)

where the model should, at minimum, support ``arg`` values that are:

-   *(Image models)* uint8 numpy arrays (HWC)

-   *(Video models)* ``eta.core.video.VideoReader`` instances

and the output ``labels`` can be any of the following:

-   A |Label| instance, in which case the labels are directly saved in the
    specified ``label_field`` of the sample

.. code-block:: python
    :linenos:

    # Single sample-level label
    sample[label_field] = labels

-   A dict mapping keys to |Label| instances. In this case, the labels are
    added as follows:

.. code-block:: python
    :linenos:

    # Multiple sample-level labels
    for key, value in labels.items():
        sample[label_field + "_" + key] = value

-   A dict mapping frame numbers to |Label| instances. In this case, the
    provided labels are interpreted as frame-level labels that should be added
    as follows:

.. code-block:: python
    :linenos:

    # Single set of per-frame labels
    sample.frames.merge(
        {
            frame_number: {label_field: label}
            for frame_number, label in labels.items()
        }
    )

-   A dict mapping frame numbers to dicts mapping keys to |Label| instances. In
    this case, the provided labels are interpreted as frame-level labels that
    should be added as follows:

.. code-block:: python
    :linenos:

    # Multiple per-frame labels
    sample.frames.merge(
        {
            frame_number: {
                label_field + "_" + name: label
                for name, label in frame_dict.items()
            }
            for frame_number, frame_dict in labels.items()
        }
    )

For models that support batching, the |Model| interface also provides a
:meth:`predict_all() <fiftyone.core.models.Model.predict_all>` method that can
provide an efficient implementation of predicting on a batch of data.

.. note:

    Builtin methods like
    :meth:`apply_model() <fiftyone.core.collections.SampleCollection.apply_model>`
    provide a ``batch_size`` parameter that can be used to control the batch
    size used when performing inference with models that support efficient
    batching.

.. note:

    PyTorch models can implement the |TorchModelMixin| mixin, in which case
    `DataLoaders <https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader>`_
    are used to efficiently feed data to the models during inference.

Embeddings
~~~~~~~~~~

Models that can compute embeddings for their input data can expose this
capability by implementing the |EmbeddingsMixin| mixin.

Inside builtin methods like
:meth:`compute_embeddings() <fiftyone.core.collections.SampleCollection.compute_embeddings>`,
embeddings for a collection of samples are generated using an analogous pattern
to the prediction code shown above, except that the embeddings are generated
using :meth:`Model.embed() <fiftyone.core.models.EmbeddingsMixin.embed>` in place of
:meth:`Model.predict() <fiftyone.core.models.Model.predict>`.

By convention,
:meth:`Model.embed() <fiftyone.core.models.EmbeddingsMixin.embed>` should
return a NumPy array containing the embedding.

.. note:

    Sample embeddings are typically 1D vectors, but this is not strictly
    required.

For models that support batching, the |EmbeddingsMixin| interface also provides
a :meth:`embed_all() <fiftyone.core.models.Model.predict_all>` method that can
provide an efficient implementation of embedding a batch of data.

API Reference
-------------

The sections below describe the full API for working with the Model Zoo.

.. _listing-zoo-models:

Listing zoo models
------------------

.. tabs::

  .. group-tab:: Python

    You can list the available zoo models via
    :meth:`list_zoo_models() <fiftyone.zoo.models.list_zoo_models>`:

    .. code-block:: python
        :linenos:

        import fiftyone.zoo.models as fozm

        available_models = fozm.list_zoo_models()

        print(available_models)

    .. code-block:: text

        ['alexnet-imagenet-torch',
        'deeplabv3-cityscapes-tf',
        'deeplabv3-mnv2-cityscapes-tf',
        ...
        'wide-resnet50-2-imagenet-torch',
        'yolo-v2-coco-tf1'
        ]

    To view the zoo models that you have downloaded, you can use
    :meth:`list_downloaded_zoo_models() <fiftyone.zoo.models.list_downloaded_zoo_models>`:

    .. code-block:: python
        :linenos:

        import fiftyone as fo
        import fiftyone.zoo.models as fozm

        downloaded_models = fozm.list_downloaded_zoo_models()
        fo.pprint(downloaded_models)

    .. code-block:: text

        {
            'alexnet-imagenet-torch': (
                '/Users/Brian/fiftyone/__models__/alexnet-owt-4df8aa71.pth',
                <fiftyone.zoo.models.ZooModel object at 0x122d2fa58>,
            ),
            'densenet121-imagenet-torch': (
                '/Users/Brian/fiftyone/__models__/densenet121-a639ec97.pth',
                <fiftyone.zoo.models.ZooModel object at 0x122d608d0>,
            ),
            ...
        }

  .. group-tab:: CLI

    You can access information about the available zoo models via the
    :ref:`fiftyone model-zoo list <cli-fiftyone-model-zoo-list>` command.

    For example, to list the available zoo models and whether you have
    downloaded them, you can execute:

    .. code-block:: shell

        fiftyone model-zoo list

    Models that have been downloaded are indicated by a checkmark in the
    ``downloaded`` column, and their location on disk is indicated by the
    ``model_path`` column.

.. _zoo-model-info:

Getting information about zoo models
------------------------------------

.. tabs::

  .. group-tab:: Python

    Each zoo model is represented by a
    :class:`ZooModel <fiftyone.zoo.models.ZooModel>` subclass, which contains
    information about the model, its package requirements and CPU/GPU support,
    and more. You can access this object for a given model via the
    :meth:`get_zoo_model() <fiftyone.zoo.models.get_zoo_model>` method.

    For example, let's print some information about a Faster R-CNN PyTorch
    model:

    .. code-block:: python
        :linenos:

        import fiftyone.zoo.models as fozm

        zoo_model = fozm.get_zoo_model("faster-rcnn-resnet50-fpn-coco-torch")

        print("***** Model description *****")
        print(zoo_model.description)

        print("\n***** Tags *****")
        print(zoo_model.tags)

        print("\n***** Requirements *****")
        print(zoo_model.requirements)

    .. code-block:: text

        ***** Model description *****
        Faster R-CNN model with ResNet-50 FPN backbone trained on COCO. Source: https://pytorch.org/docs/stable/torchvision/models.html

        ***** Tags *****
        ['detection', 'coco', 'torch']

        ***** Requirements *****
        {
            "packages": [
                "torch",
                "torchvision"
            ],
            "cpu": {
                "support": true
            },
            "gpu": {
                "support": true
            }
        }

    When a zoo model is downloaded, you can use
    :meth:`find_zoo_model() <fiftyone.zoo.models.find_zoo_model>` to locate the
    downloaded model on disk:

    For example, let's get the path on disk to the Faster R-CNN model
    referenced above (assuming it is downloaded):

    .. code-block:: python
        :linenos:

        import fiftyone.zoo.models as fozm

        model_path = fozm.find_zoo_model("faster-rcnn-resnet50-fpn-coco-torch")

  .. group-tab:: CLI

    You can view detailed information about a model (either downloaded or
    not) via the :ref:`fiftyone model-zoo info <cli-fiftyone-model-zoo-info>`
    command.

    For example, you can view information about a Faster R-CNN PyTorch model:

    .. code-block:: shell

        fiftyone model-zoo info faster-rcnn-resnet50-fpn-coco-torch

    .. code-block:: text

        ***** Model description *****
        {
            "base_name": "faster-rcnn-resnet50-fpn-coco-torch",
            "base_filename": "fasterrcnn_resnet50_fpn_coco-258fb6c6.pth",
            "version": null,
            "description": "Faster R-CNN model with ResNet-50 FPN backbone trained on COCO. Source: https://pytorch.org/docs/stable/torchvision/models.html",
            "manager": {
                "type": "fiftyone.core.models.ModelManager",
                "config": {
                    "url": "https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth"
                }
            },
            "default_deployment_config_dict": {
                "type": "fiftyone.zoo.models.torch.TorchvisionImageModel",
                "config": {
                    "entrypoint_fcn": "torchvision.models.detection.faster_rcnn.fasterrcnn_resnet50_fpn",
                    "entrypoint_args": {
                        "pretrained": true
                    },
                    "output_processor_cls": "fiftyone.utils.torch.DetectorOutputProcessor",
                    "labels_path": "{{eta-resources}}/ms-coco-labels.txt"
                }
            },
            "requirements": {
                "packages": [
                    "torch",
                    "torchvision"
                ],
                "cpu": {
                    "support": true
                },
                "gpu": {
                    "support": true
                }
            },
            "tags": [
                "detection",
                "coco",
                "torch"
            ],
            "date_added": "2020-12-11T13:45:51"
        }

        ***** Model location *****
        /Users/Brian/fiftyone/__models__/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth

.. _downloading-zoo-models:

Downloading zoo models
----------------------

.. tabs::

  .. group-tab:: Python

    You can download zoo models from the web via
    :meth:`download_zoo_model() <fiftyone.zoo.models.download_zoo_model>`.

    For example, let's download a Faster R-CNN PyTorch model:

    .. code-block:: python
        :linenos:

        import fiftyone.zoo.models as fozm

        model_path = fozm.download_zoo_model("faster-rcnn-resnet50-fpn-coco-torch")

    .. code-block:: text

        Downloading model from 'https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth'...
         100% |██████████████████████████████████|    1.2Gb/1.2Gb [4.7s elapsed, 0s remaining, 294.7Mb/s]

  .. group-tab:: CLI

    You can download zoo models from the web via the
    :ref:`fiftyone model-zoo download <cli-fiftyone-model-zoo-download>`
    command.

    For example, you can download a Faster R-CNN PyTorch model as follows:

    .. code-block:: shell

        fiftyone model-zoo download faster-rcnn-resnet50-fpn-coco-torch

    .. code-block:: text

        Downloading model from 'https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth'...
         100% |██████████████████████████████████|    1.2Gb/1.2Gb [4.7s elapsed, 0s remaining, 294.7Mb/s]

.. _model-zoo-requirements:

Installing zoo model requirements
---------------------------------

.. tabs::

  .. group-tab:: Python

    Some models in the FiftyOne Model Zoo may require packages that are not
    installed by default when FiftyOne is installed.

    You can check to see if your current environment satisfies the requirements
    for a particular zoo model via
    :meth:`ensure_zoo_model_requirements() <fiftyone.zoo.models.ensure_zoo_model_requirements>`:

    .. code-block:: python
        :linenos:

        import fiftyone.zoo.models as fozm

        # Raises an error if the requirements are not satisfied
        fozm.ensure_zoo_model_requirements("faster-rcnn-resnet50-fpn-coco-torch")

    You can also use
    :meth:`install_zoo_model_requirements() <fiftyone.zoo.models.install_zoo_model_requirements>`
    to install any necessary packages for a particular model:

    .. code-block:: python
        :linenos:

        import fiftyone.zoo.models as fozm

        fozm.install_zoo_model_requirements("faster-rcnn-resnet50-fpn-coco-torch")

  .. group-tab:: CLI

    Some models in the FiftyOne Model Zoo may require packages that are not
    installed by default when FiftyOne is installed.

    You can view the requirements for a zoo model via the
    :ref:`fiftyone model-zoo requirements <cli-fiftyone-model-zoo-requirements>`
    command:

    .. code-block:: shell

        fiftyone model-zoo requirements faster-rcnn-resnet50-fpn-coco-torch

    .. code-block:: text

        ***** Model requirements *****
        {
            "packages": [
                "torch",
                "torchvision"
            ],
            "cpu": {
                "support": true
            },
            "gpu": {
                "support": true
            }
        }

        ***** Current machine *****
        GPU: no

    You can use the `--ensure` flag to check to see if your current environment
    satisfies the requirements for a particular zoo model:

    .. code-block:: shell

        # Raises an error if the requirements are not satisfied
        fiftyone model-zoo requirements --ensure faster-rcnn-resnet50-fpn-coco-torch

    You can also use the `--install` flag to install any necessary packages for
    a particular zoo model:

    .. code-block:: shell

        fiftyone model-zoo requirements --install faster-rcnn-resnet50-fpn-coco-torch

.. _loading-zoo-models:

Loading zoo models
------------------

You can load a zoo model via
:meth:`load_zoo_model() <fiftyone.zoo.models.load_zoo_model>`.

By default, the model will be automatically downloaded from the web the first
time you access it if it is not already downloaded:

.. code-block:: python
    :linenos:

    import fiftyone.zoo.models as fozm

    # The model will be downloaded from the web the first time you access it
    model = fozm.load_zoo_model("faster-rcnn-resnet50-fpn-coco-torch")

You can also provide additional arguments to
:meth:`load_zoo_model() <fiftyone.zoo.models.load_zoo_model>` to customize
the import behavior:

.. code-block:: python
    :linenos:

    # Load the zoo model and install any necessary requirements in order to
    # use it (logging warnings if any issues arise)
    model = fozm.load_zoo_model(
        "faster-rcnn-resnet50-fpn-coco-torch",
        install_requirements=True,
        error_level=1,
    )

.. note::

    By default, FiftyOne will attempt to ensure that any requirements such as
    Python packages or CUDA versions are satisfied before loading the model,
    and an error will be raised if a requirement is not satisfied.

    You can customize this behavior via the ``error_level`` argument to
    :meth:`load_zoo_model() <fiftyone.zoo.models.load_zoo_model>`, or you can
    permanently adjust this behavior by setting the ``requirement_error_level``
    parameter of your :ref:`FiftyOne config <configuring-fiftyone>`.

.. _applying-zoo-models:

Applying zoo models
-------------------

.. tabs::

  .. group-tab:: Python

    You can run inference on a dataset (or a subset of it specified by a
    |DatasetView|) with a zoo model by loading it and then calling
    :meth:`apply_model() <fiftyone.core.collections.SampleCollection.apply_model>`:

    For example, the snippet below loads the
    ``faster-rcnn-resnet50-fpn-coco-torch`` model from the Model Zoo and
    applies it to 10 random images from the ``quickstart`` dataset from the
    Dataset Zoo:

    .. code-block:: python
        :linenos:

        import fiftyone.zoo as foz
        import fiftyone.zoo.models as fozm

        # Load zoo model
        model = fozm.load_zoo_model("faster-rcnn-resnet50-fpn-coco-torch")

        # Load zoo dataset
        dataset = foz.load_zoo_dataset("quickstart")
        samples = dataset.take(10)

        # Run inference
        samples.apply_model(model, label_field="faster_rcnn")

  .. group-tab:: CLI

    You can run inference on a dataset with a zoo model via the
    :ref:`fiftyone model-zoo apply <cli-fiftyone-model-zoo-apply>` command.

    For example, the snippet below loads the ``quickstart`` dataset from the
    Dataset Zoo and applies the ``faster-rcnn-resnet50-fpn-coco-torch`` model
    from the Model Zoo to it:

    .. code-block:: shell

        # Load zoo dataset
        fiftyone zoo load quickstart

        # Apply zoo model
        fiftyone model-zoo apply \
            quickstart \                            # dataset
            faster-rcnn-resnet50-fpn-coco-torch \   # model
            faster_rcnn                             # label field

.. _generating-zoo-model-embeddings:

Generating embeddings with zoo models
-------------------------------------

.. tabs::

  .. group-tab:: Python

    Many models in the Model Zoo expose embeddings for their predictions. You
    can determine if a model supports embeddings by loading it and checking the
    :meth:`Model.has_embeddings <fiftyone.core.models.Model.has_embeddings>`
    attribute:

    .. code-block:: python
        :linenos:

        import fiftyone.zoo.models as fozm

        # Load zoo model
        model = fozm.load_zoo_model("inception-v3-imagenet-torch")

        # Check if model exposes embeddings
        model.has_embeddings  # True

    For models that expose embeddings, you can generate embeddings for all
    samples in a dataset (or a subset of it specified by a |DatasetView|) by
    calling
    :meth:`compute_embeddings() <fiftyone.core.collections.SampleCollection.compute_embeddings>`:

    .. code-block:: python
        :linenos:

        import fiftyone.zoo as foz
        import fiftyone.zoo.models as fozm

        # Load zoo model
        model = fozm.load_zoo_model("inception-v3-imagenet-torch")
        model.has_embeddings  # True

        # Load zoo dataset
        dataset = foz.load_zoo_dataset("quickstart")
        samples = dataset.take(10)

        # Generate embeddings for each sample and return them in a
        # `num_samples x dim` array
        embeddings = samples.compute_embeddings(model)

        # Generate embeddings for each sample and store them in a sample field
        samples.compute_embeddings(model, embeddings_field="embeddings")

    You can also use
    :meth:`compute_patch_embeddings() <fiftyone.core.collections.SampleCollection.compute_patch_embeddings>`
    to generate embeddings for image patches defined by another label field,
    e.g,. the detections generated by a detection model.

  .. group-tab:: CLI

    For models that expose embeddings, you can generate embeddings for all
    samples in a dataset via the
    :ref:`fiftyone model-zoo embed <cli-fiftyone-model-zoo-embed>` command.

    For example, the snippet below loads the ``quickstart`` dataset from the
    Dataset Zoo and generates embeddings for each sample using the
    ``inception-v3-imagenet-torch`` model from the Model Zoo:

    .. code-block:: shell

        # Load zoo dataset
        fiftyone zoo load quickstart

        # Generate embeddings via zoo model
        fiftyone model-zoo embed \
            quickstart \                            # dataset
            inception-v3-imagenet-torch \           # model
            embeddings                              # embeddings field

Controlling where zoo models are downloaded
-------------------------------------------

By default, zoo models are downloaded into subdirectories of
``fiftyone.config.model_zoo_dir`` corresponding to their names.

You can customize this backend by modifying the ``model_zoo_dir`` setting of
your :ref:`FiftyOne config <configuring-fiftyone>`.

.. tabs::

    .. group-tab:: JSON

        Directly edit your FiftyOne config at `~/.fiftyone/config.json`:

        .. code-block:: shell

            # Print your current config
            fiftyone config

            # Locate your config (and edit the `model_zoo_dir` field)
            fiftyone constants FIFTYONE_CONFIG_PATH

    .. group-tab:: Environment

        Set the ``FIFTYONE_MODEL_ZOO_DIR`` environment variable:

        .. code-block:: shell

            # Customize where zoo models are downloaded
            export FIFTYONE_MODEL_ZOO_DIR=/your/custom/directory

    .. group-tab:: Code

        Set the `model_zoo_dir` config setting from Python code:

        .. code-block:: python
            :linenos:

            # Customize where zoo models are downloaded
            import fiftyone.core.config as foc

            foc.set_config_settings(model_zoo_dir="/your/custom/directory")

.. _deleting-zoo-models:

Deleting zoo models
-------------------

.. tabs::

  .. group-tab:: Python

    You can delete the local copy of a zoo model via
    :meth:`delete_zoo_model() <fiftyone.zoo.models.delete_zoo_model>`:

    .. code-block:: python
        :linenos:

        import fiftyone.zoo.models as fozm

        fozm.delete_zoo_model("faster-rcnn-resnet50-fpn-coco-torch")

  .. group-tab:: CLI

    You can delete the local copy of a zoo model via the
    :ref:`fiftyone model-zoo delete <cli-fiftyone-model-zoo-delete>` command:

    .. code-block:: shell

        fiftyone model-zoo delete faster-rcnn-resnet50-fpn-coco-torch

.. _adding-zoo-models:

Adding models to the zoo
------------------------

We frequently add new models to the Model Zoo, which will automatically become
accessible to you when you update your FiftyOne package.

.. note::

    FiftyOne is open source! You are welcome to contribute models to the public
    model zoo by submitting a pull request to
    `the GitHub repository <https://github.com/voxel51/fiftyone>`_.

You can also add your own models to your local model zoo, enabling you to work
with these models via the ``fiftyone.zoo.models`` package and the CLI using the
same syntax that you would with publicly available models.

To add model(s) to your local zoo, you simply write a JSON manifest file in
the format below to tell FiftyOne about the model(s). For example, the manifest
below adds a second copy of the ``yolo-v2-coco-tf1`` model to the zoo under the
alias ``yolo-v2-coco-tf1-high-conf`` that only returns predictions whose
confidence is at least 0.5:

.. code-block:: json

    {
        "models": [
            {
                "base_name": "yolo-v2-coco-tf1-high-conf",
                "base_filename": "yolo-v2-coco-high-conf.weights",
                "version": null,
                "description": "A YOLOv2 model with confidence threshold set to 0.5",
                "manager": {
                    "type": "fiftyone.core.models.ModelManager",
                    "config": {
                        "google_drive_id": "1ajuPZws47SOw3xJc4Wvk1yuiB3qv8ycr"
                    }
                },
                "default_deployment_config_dict": {
                    "type": "fiftyone.core.eta_utils.ETAModel",
                    "config": {
                        "type": "eta.detectors.YOLODetector",
                        "config": {
                            "config_dir": "{{eta}}/tensorflow/darkflow/cfg/",
                            "config_path": "{{eta}}/tensorflow/darkflow/cfg/yolo.cfg",
                            "confidence_thresh": 0.5
                        }
                    }
                },
                "requirements": {
                    "cpu": {
                        "support": true,
                        "packages": ["tensorflow<2"]
                    },
                    "gpu": {
                        "support": true,
                        "packages": ["tensorflow-gpu<2"]
                    }
                },
                "tags": ["detection", "coco", "tf1"],
                "date_added": "2020-12-11 13:45:51"
            }
        ]
    }

.. note::

    Adjusting the hard-coded threshold of the above model is possible via
    JSON-only changes in this case because the underlying
    `eta.detectors.YOLODetector <https://github.com/voxel51/eta/blob/develop/eta/detectors/yolo.py>`_
    class exposes this as a parameter.

    In practice, there is no need to hard-code confidence thresholds in models,
    since the
    :meth:`apply_model() <fiftyone.core.collections.SampleCollection.apply_model>`
    method supports supplying an optional confidence threshold that is applied
    post-facto to the predictions generated by any model.

Models manifest JSON files should have a ``models`` key that contains a list
of serialized
:class:`ZooModel class definitions <fiftyone.zoo.models.ZooModel>` that
describe how to download and load the model.

Finally, expose your new models(s) to FiftyOne by adding your manifest to the
``model_zoo_manifest_paths`` parameter of your
:ref:`FiftyOne config <configuring-fiftyone>`. One way to do this is to set the
``FIFTYONE_MODEL_ZOO_MANIFEST_PATHS`` environment variable:

.. code-block:: shell

    export FIFTYONE_MODEL_ZOO_MANIFEST_PATHS=/path/to/custom/manifest.json

Now you can load and apply the ``yolo-v2-coco-tf1-high-conf`` model as you
would any other zoo model:

.. code-block:: python

    import fiftyone as fo
    import fiftyone.zoo.models as fozm

    # Load custom model
    model = fozm.load_zoo_model("yolo-v2-coco-tf1-high-conf")

    # Apply model to a dataset
    dataset = fo.load_dataset(...)
    dataset.apply_model(model, label_field="predictions")
