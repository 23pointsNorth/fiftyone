{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Evaluate Detection Model with FiftyOne\n",
    "\n",
    "This walkthrough demonstrates how use FiftyOne to perform hands-on evaluation of your detection model.\n",
    "\n",
    "It covers the following concepts:\n",
    "* Loading a dataset with detections\n",
    "* Adding detection predictions\n",
    "* Sample-wise MSCOCO evaluation\n",
    "* Sorting and searching samples by model performance\n",
    "* Visualizing true-positives and false-positives\n",
    "* Querying your dataset for a custom insight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "Install `torch` and `torchvision`, if necessary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify as necessary (e.g., GPU install). See https://pytorch.org for options\n",
    "!pip install torch\n",
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the FiftyOne zoo and download the MSCOCO validation split to `~/fiftyone/coco-2017/validation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "import torch, torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 'validation' already downloaded\n",
      "Loading 'coco-2017' split 'validation'\n",
      " 100%  5000/5000 [17.3s elapsed, 0s remai\n"
     ]
    }
   ],
   "source": [
    "dataset = foz.load_zoo_dataset(\"coco-2017\", \"validation\")\n",
    "dataset.persistent=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize Faster-RCNN and download pretrained weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FasterRCNN(\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
       "  )\n",
       "  (backbone): BackboneWithFPN(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): FrozenBatchNorm2d()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d()\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d()\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d()\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d()\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (inner_blocks): ModuleList(\n",
       "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (layer_blocks): ModuleList(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (extra_blocks): LastLevelMaxPool()\n",
       "    )\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign()\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=91, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=364, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the model on gpu if it is available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Predictions\n",
    "Run Faster-RCNN on every sample in the validation dataset and add detections to our FiftyOne dataset.\n",
    "Predictions are added to each sample in a new field we will call `faster_rcnn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erich/venvs/fo/lib/python3.6/site-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished adding predictions\n"
     ]
    }
   ],
   "source": [
    "# ETA is installed with FiftyOne\n",
    "# etai provides functionality to read images into memory\n",
    "import fiftyone.core.utils as fou\n",
    "import eta.core.image as etai\n",
    "import json\n",
    "from torchvision.transforms import functional as TF\n",
    "\n",
    "labels_path = \"/home/erich/fiftyone/coco-2017/validation/labels.json\"\n",
    "with open(labels_path, \"r\") as labels_file:\n",
    "    classes = json.load(labels_file)[\"classes\"]\n",
    "\n",
    "# Add predictions\n",
    "with fou.ProgressBar() as pb:\n",
    "    for sample in pb(dataset):\n",
    "        image = etai.read(sample.filepath)\n",
    "        image = TF.to_tensor(image).to(device)\n",
    "        c,h,w = image.shape\n",
    "\n",
    "        preds = model([image])[0]\n",
    "\n",
    "        labels = preds[\"labels\"].cpu().detach().numpy()\n",
    "        scores = preds[\"scores\"].cpu().detach().numpy()\n",
    "        boxes = preds[\"boxes\"].cpu().detach().numpy()\n",
    "\n",
    "        detections = []\n",
    "        for label, score, box in zip(labels, scores, boxes):\n",
    "            # Compute relative bounding box coordinates\n",
    "            x1, y1, x2, y2 = box\n",
    "            rel_box = [x1/w, y1/h, (x2-x1)/w, (y2-y1)/h]\n",
    "\n",
    "            detections.append(fo.Detection(\n",
    "                label=classes[label],\n",
    "                bounding_box=rel_box,\n",
    "                confidence=score\n",
    "            ))\n",
    "\n",
    "        sample[\"faster_rcnn\"] = fo.Detections(\n",
    "            detections=detections\n",
    "        )\n",
    "        sample.save()\n",
    "\n",
    "print(\"Finished adding predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Detections\n",
    "Use MSCOCO detection evaluation provided within FiftyOne to threshold detections and compute AP for each sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Threshold all detections to remove any detections lower than 0.5 confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "from fiftyone import ViewField as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "faster_rcnn_75 = dataset.filter_detections(\"faster_rcnn\", F(\"confidence\")>0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SampleView: {\n",
       "    'dataset_name': 'coco-2017-validation',\n",
       "    'id': '5f2470ee75acf119229ee910',\n",
       "    'filepath': '/home/erich/fiftyone/coco-2017/validation/data/000001.jpg',\n",
       "    'tags': BaseList(['validation']),\n",
       "    'metadata': None,\n",
       "    'ground_truth': <Detections: {\n",
       "        'detections': BaseList([\n",
       "            <Detection: {\n",
       "                'id': '5f2470ee75acf119229ee586',\n",
       "                'label': 'potted plant',\n",
       "                'bounding_box': array([0.37028125, 0.33453052, 0.03859375, 0.16314554]),\n",
       "                'confidence': None,\n",
       "                'attributes': BaseDict({\n",
       "                    'area': <NumericAttribute: {'value': 531.8071000000001}>,\n",
       "                    'iscrowd': <NumericAttribute: {'value': 0.0}>,\n",
       "                }),\n",
       "            }>,\n",
       "            <Detection: {\n",
       "                'id': '5f2470ee75acf119229ee587',\n",
       "                'label': 'tv',\n",
       "                'bounding_box': array([0.01098438, 0.39380282, 0.2333125 , 0.22269953]),\n",
       "                'confidence': None,\n",
       "                'attributes': BaseDict({\n",
       "                    'area': <NumericAttribute: {'value': 13244.657700000002}>,\n",
       "                    'iscrowd': <NumericAttribute: {'value': 0.0}>,\n",
       "                }),\n",
       "            }>,\n",
       "            <Detection: {\n",
       "                'id': '5f2470ee75acf119229ee588',\n",
       "                'label': 'tv',\n",
       "                'bounding_box': array([0.87064063, 0.49105634, 0.12710937, 0.18481221]),\n",
       "                'confidence': None,\n",
       "                'attributes': BaseDict({\n",
       "                    'area': <NumericAttribute: {'value': 5833.117949999999}>,\n",
       "                    'iscrowd': <NumericAttribute: {'value': 0.0}>,\n",
       "                }),\n",
       "            }>,\n",
       "            <Detection: {\n",
       "                'id': '5f2470ee75acf119229ee589',\n",
       "                'label': 'chair',\n",
       "                'bounding_box': array([0.56090625, 0.51185446, 0.0875    , 0.24138498]),\n",
       "                'confidence': None,\n",
       "                'attributes': BaseDict({\n",
       "                    'area': <NumericAttribute: {'value': 2245.34355}>,\n",
       "                    'iscrowd': <NumericAttribute: {'value': 0.0}>,\n",
       "                }),\n",
       "            }>,\n",
       "            <Detection: {\n",
       "                'id': '5f2470ee75acf119229ee58a',\n",
       "                'label': 'chair',\n",
       "                'bounding_box': array([0.45420312, 0.51173709, 0.09660937, 0.23117371]),\n",
       "                'confidence': None,\n",
       "                'attributes': BaseDict({\n",
       "                    'area': <NumericAttribute: {'value': 1833.7840000000017}>,\n",
       "                    'iscrowd': <NumericAttribute: {'value': 0.0}>,\n",
       "                }),\n",
       "            }>,\n",
       "            <Detection: {\n",
       "                'id': '5f2470ee75acf119229ee58b',\n",
       "                'label': 'chair',\n",
       "                'bounding_box': array([0.645625  , 0.52349765, 0.04714063, 0.19098592]),\n",
       "                'confidence': None,\n",
       "                'attributes': BaseDict({\n",
       "                    'area': <NumericAttribute: {'value': 1289.3734500000014}>,\n",
       "                    'iscrowd': <NumericAttribute: {'value': 0.0}>,\n",
       "                }),\n",
       "            }>,\n",
       "            <Detection: {\n",
       "                'id': '5f2470ee75acf119229ee58c',\n",
       "                'label': 'chair',\n",
       "                'bounding_box': array([0.4959375 , 0.51464789, 0.03371875, 0.02720657]),\n",
       "                'confidence': None,\n",
       "                'attributes': BaseDict({\n",
       "                    'area': <NumericAttribute: {'value': 210.14820000000023}>,\n",
       "                    'iscrowd': <NumericAttribute: {'value': 0.0}>,\n",
       "                }),\n",
       "            }>,\n",
       "            <Detection: {\n",
       "                'id': '5f2470ee75acf119229ee58d',\n",
       "                'label': 'person',\n",
       "                'bounding_box': array([0.645     , 0.36997653, 0.08289062, 0.32396714]),\n",
       "                'confidence': None,\n",
       "                'attributes': BaseDict({\n",
       "                    'area': <NumericAttribute: {'value': 2913.1103999999987}>,\n",
       "                    'iscrowd': <NumericAttribute: {'value': 0.0}>,\n",
       "                }),\n",
       "            }>,\n",
       "            <Detection: {\n",
       "                'id': '5f2470ee75acf119229ee58e',\n",
       "                'label': 'person',\n",
       "                'bounding_box': array([0.60067187, 0.40424883, 0.023625  , 0.08389671]),\n",
       "                'confidence': None,\n",
       "                'attributes': BaseDict({\n",
       "                    'area': <NumericAttribute: {'value': 435.1449499999997}>,\n",
       "                    'iscrowd': <NumericAttribute: {'value': 0.0}>,\n",
       "                }),\n",
       "            }>,\n",
       "            <Detection: {\n",
       "                'id': '5f2470ee75acf119229ee58f',\n",
       "                'label': 'microwave',\n",
       "                'bounding_box': array([0.80034375, 0.48298122, 0.02303125, 0.03748826]),\n",
       "                'confidence': None,\n",
       "                'attributes': BaseDict({\n",
       "                    'area': <NumericAttribute: {'value': 217.71919999999997}>,\n",
       "                    'iscrowd': <NumericAttribute: {'value': 0.0}>,\n",
       "                }),\n",
       "            }>,\n",
       "            <Detection: {\n",
       "                'id': '5f2470ee75acf119229ee590',\n",
       "                'label': 'refrigerator',\n",
       "                'bounding_box': array([0.77046875, 0.40924883, 0.03170312, 0.25424883]),\n",
       "                'confidence': None,\n",
       "                'attributes': BaseDict({\n",
       "                    'area': <NumericAttribute: {'value': 2089.9747999999986}>,\n",
       "                    'iscrowd': <NumericAttribute: {'value': 0.0}>,\n",
       "                }),\n",
       "            }>,\n",
       "            <Detection: {\n",
       "                'id': '5f2470ee75acf119229ee591',\n",
       "                'label': 'book',\n",
       "                'bounding_box': array([0.94495312, 0.71805164, 0.02240625, 0.10730047]),\n",
       "                'confidence': None,\n",
       "                'attributes': BaseDict({\n",
       "                    'area': <NumericAttribute: {'value': 338.60884999999973}>,\n",
       "                    'iscrowd': <NumericAttribute: {'value': 0.0}>,\n",
       "                }),\n",
       "            }>,\n",
       "            <Detection: {\n",
       "                'id': '5f2470ee75acf119229ee592',\n",
       "                'label': 'book',\n",
       "                'bounding_box': array([0.9581875 , 0.72356808, 0.020125  , 0.10901408]),\n",
       "                'confidence': None,\n",
       "                'attributes': BaseDict({\n",
       "                    'area': <NumericAttribute: {'value': 322.5935999999982}>,\n",
       "                    'iscrowd': <NumericAttribute: {'value': 0.0}>,\n",
       "                }),\n",
       "            }>,\n",
       "            <Detection: {\n",
       "                'id': '5f2470ee75acf119229ee593',\n",
       "                'label': 'clock',\n",
       "                'bounding_box': array([0.69964063, 0.28431925, 0.02182813, 0.0513615 ]),\n",
       "                'confidence': None,\n",
       "                'attributes': BaseDict({\n",
       "                    'area': <NumericAttribute: {'value': 225.6642000000005}>,\n",
       "                    'iscrowd': <NumericAttribute: {'value': 0.0}>,\n",
       "                }),\n",
       "            }>,\n",
       "            <Detection: {\n",
       "                'id': '5f2470ee75acf119229ee594',\n",
       "                'label': 'vase',\n",
       "                'bounding_box': array([0.85790625, 0.7263615 , 0.0573125 , 0.21049296]),\n",
       "                'confidence': None,\n",
       "                'attributes': BaseDict({\n",
       "                    'area': <NumericAttribute: {'value': 2171.6188500000007}>,\n",
       "                    'iscrowd': <NumericAttribute: {'value': 0.0}>,\n",
       "                }),\n",
       "            }>,\n",
       "            <Detection: {\n",
       "                'id': '5f2470ee75acf119229ee595',\n",
       "                'label': 'vase',\n",
       "                'bounding_box': array([0.5480625 , 0.49023474, 0.01776563, 0.05293427]),\n",
       "                'confidence': None,\n",
       "                'attributes': BaseDict({\n",
       "                    'area': <NumericAttribute: {'value': 178.18510000000012}>,\n",
       "                    'iscrowd': <NumericAttribute: {'value': 0.0}>,\n",
       "                }),\n",
       "            }>,\n",
       "            <Detection: {\n",
       "                'id': '5f2470ee75acf119229ee596',\n",
       "                'label': 'chair',\n",
       "                'bounding_box': array([0.64414063, 0.51413146, 0.01504688, 0.02938967]),\n",
       "                'confidence': None,\n",
       "                'attributes': BaseDict({\n",
       "                    'area': <NumericAttribute: {'value': 90.98724999999988}>,\n",
       "                    'iscrowd': <NumericAttribute: {'value': 0.0}>,\n",
       "                }),\n",
       "            }>,\n",
       "            <Detection: {\n",
       "                'id': '5f2470ee75acf119229ee597',\n",
       "                'label': 'vase',\n",
       "                'bounding_box': array([0.3769375 , 0.457723  , 0.02221875, 0.04138498]),\n",
       "                'confidence': None,\n",
       "                'attributes': BaseDict({\n",
       "                    'area': <NumericAttribute: {'value': 189.56010000000012}>,\n",
       "                    'iscrowd': <NumericAttribute: {'value': 0.0}>,\n",
       "                }),\n",
       "            }>,\n",
       "            <Detection: {\n",
       "                'id': '5f2470ee75acf119229ee598',\n",
       "                'label': 'vase',\n",
       "                'bounding_box': array([0.52623438, 0.46830986, 0.01520313, 0.0392723 ]),\n",
       "                'confidence': None,\n",
       "                'attributes': BaseDict({\n",
       "                    'area': <NumericAttribute: {'value': 120.23200000000004}>,\n",
       "                    'iscrowd': <NumericAttribute: {'value': 0.0}>,\n",
       "                }),\n",
       "            }>,\n",
       "            <Detection: {\n",
       "                'id': '5f2470ee75acf119229ee599',\n",
       "                'label': 'dining table',\n",
       "                'bounding_box': array([0.50189062, 0.54276995, 0.1961875 , 0.20875587]),\n",
       "                'confidence': None,\n",
       "                'attributes': BaseDict({\n",
       "                    'area': <NumericAttribute: {'value': 2362.4897499999984}>,\n",
       "                    'iscrowd': <NumericAttribute: {'value': 0.0}>,\n",
       "                }),\n",
       "            }>,\n",
       "        ]),\n",
       "    }>,\n",
       "    'faster_rcnn': <Detections: {\n",
       "        'detections': BaseList([\n",
       "            <Detection: {\n",
       "                'id': '5f24710475acf11922a01b32',\n",
       "                'label': 'chair',\n",
       "                'bounding_box': array([0.45553966, 0.50822879, 0.09678884, 0.23788502]),\n",
       "                'confidence': 0.9970741271972656,\n",
       "                'attributes': BaseDict({}),\n",
       "            }>,\n",
       "            <Detection: {\n",
       "                'id': '5f24710475acf11922a01b33',\n",
       "                'label': 'tv',\n",
       "                'bounding_box': array([0.00964072, 0.39463584, 0.23199208, 0.2261599 ]),\n",
       "                'confidence': 0.9945569038391113,\n",
       "                'attributes': BaseDict({}),\n",
       "            }>,\n",
       "            <Detection: {\n",
       "                'id': '5f24710475acf11922a01b34',\n",
       "                'label': 'chair',\n",
       "                'bounding_box': array([0.57289572, 0.50834423, 0.08778524, 0.23011991]),\n",
       "                'confidence': 0.9926774501800537,\n",
       "                'attributes': BaseDict({}),\n",
       "            }>,\n",
       "            <Detection: {\n",
       "                'id': '5f24710475acf11922a01b35',\n",
       "                'label': 'potted plant',\n",
       "                'bounding_box': array([0.3590044 , 0.40898727, 0.05864363, 0.09255989]),\n",
       "                'confidence': 0.9890421032905579,\n",
       "                'attributes': BaseDict({}),\n",
       "            }>,\n",
       "            <Detection: {\n",
       "                'id': '5f24710475acf11922a01b36',\n",
       "                'label': 'person',\n",
       "                'bounding_box': array([0.66548634, 0.37520399, 0.06045194, 0.32670067]),\n",
       "                'confidence': 0.9799464344978333,\n",
       "                'attributes': BaseDict({}),\n",
       "            }>,\n",
       "            <Detection: {\n",
       "                'id': '5f24710475acf11922a01b37',\n",
       "                'label': 'clock',\n",
       "                'bounding_box': array([0.70145712, 0.28450451, 0.01858282, 0.04975667]),\n",
       "                'confidence': 0.9778839349746704,\n",
       "                'attributes': BaseDict({}),\n",
       "            }>,\n",
       "            <Detection: {\n",
       "                'id': '5f24710475acf11922a01b38',\n",
       "                'label': 'vase',\n",
       "                'bounding_box': array([0.26097288, 0.54753908, 0.02981098, 0.07960353]),\n",
       "                'confidence': 0.9736015200614929,\n",
       "                'attributes': BaseDict({}),\n",
       "            }>,\n",
       "            <Detection: {\n",
       "                'id': '5f24710475acf11922a01b39',\n",
       "                'label': 'vase',\n",
       "                'bounding_box': array([0.37782567, 0.46532594, 0.01794972, 0.03370631]),\n",
       "                'confidence': 0.9675768613815308,\n",
       "                'attributes': BaseDict({}),\n",
       "            }>,\n",
       "            <Detection: {\n",
       "                'id': '5f24710475acf11922a01b3a',\n",
       "                'label': 'dining table',\n",
       "                'bounding_box': array([0.74585967, 0.80652178, 0.24045224, 0.18531864]),\n",
       "                'confidence': 0.9660236239433289,\n",
       "                'attributes': BaseDict({}),\n",
       "            }>,\n",
       "            <Detection: {\n",
       "                'id': '5f24710475acf11922a01b3b',\n",
       "                'label': 'chair',\n",
       "                'bounding_box': array([0.64378619, 0.51624961, 0.04576092, 0.20378571]),\n",
       "                'confidence': 0.9659411907196045,\n",
       "                'attributes': BaseDict({}),\n",
       "            }>,\n",
       "            <Detection: {\n",
       "                'id': '5f24710475acf11922a01b3c',\n",
       "                'label': 'potted plant',\n",
       "                'bounding_box': array([0.52250581, 0.41954599, 0.05403304, 0.11022057]),\n",
       "                'confidence': 0.9121472835540771,\n",
       "                'attributes': BaseDict({}),\n",
       "            }>,\n",
       "            <Detection: {\n",
       "                'id': '5f24710475acf11922a01b3d',\n",
       "                'label': 'refrigerator',\n",
       "                'bounding_box': array([0.76856546, 0.3947213 , 0.03324966, 0.26151286]),\n",
       "                'confidence': 0.8987162709236145,\n",
       "                'attributes': BaseDict({}),\n",
       "            }>,\n",
       "            <Detection: {\n",
       "                'id': '5f24710475acf11922a01b3e',\n",
       "                'label': 'bottle',\n",
       "                'bounding_box': array([0.86002293, 0.69701468, 0.05672216, 0.24172243]),\n",
       "                'confidence': 0.8675008416175842,\n",
       "                'attributes': BaseDict({}),\n",
       "            }>,\n",
       "            <Detection: {\n",
       "                'id': '5f24710475acf11922a01b3f',\n",
       "                'label': 'refrigerator',\n",
       "                'bounding_box': array([0.6941112 , 0.38948618, 0.10563045, 0.28423392]),\n",
       "                'confidence': 0.8546730875968933,\n",
       "                'attributes': BaseDict({}),\n",
       "            }>,\n",
       "            <Detection: {\n",
       "                'id': '5f24710475acf11922a01b40',\n",
       "                'label': 'vase',\n",
       "                'bounding_box': array([0.52758965, 0.47423951, 0.01503286, 0.03109902]),\n",
       "                'confidence': 0.8275289535522461,\n",
       "                'attributes': BaseDict({}),\n",
       "            }>,\n",
       "            <Detection: {\n",
       "                'id': '5f24710475acf11922a01b41',\n",
       "                'label': 'vase',\n",
       "                'bounding_box': array([0.56387463, 0.5031359 , 0.01993566, 0.03956292]),\n",
       "                'confidence': 0.8236485719680786,\n",
       "                'attributes': BaseDict({}),\n",
       "            }>,\n",
       "            <Detection: {\n",
       "                'id': '5f24710475acf11922a01b42',\n",
       "                'label': 'vase',\n",
       "                'bounding_box': array([0.54794497, 0.48338769, 0.01691928, 0.05922258]),\n",
       "                'confidence': 0.7912060618400574,\n",
       "                'attributes': BaseDict({}),\n",
       "            }>,\n",
       "        ]),\n",
       "    }>,\n",
       "}>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faster_rcnn_75.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100%  5000/500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5000, 0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.clone_field(\"faster_rcnn\", \"faster_rcnn_75\", samples=faster_rcnn_75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Match detections to ground truth and compute true and false positives according to MSCOCO evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone.utils.cocoeval as fouc\n",
    "\n",
    "fouc.evaluate_detections(dataset, \"faster_rcnn_75\", \"ground_truth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name:           coco-2017-validation\n",
       "Persistent:     True\n",
       "Num samples:    5000\n",
       "Tags:           ['validation']\n",
       "Sample fields:\n",
       "    filepath:       fiftyone.core.fields.StringField\n",
       "    tags:           fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
       "    metadata:       fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.Metadata)\n",
       "    ground_truth:   fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
       "    faster_rcnn:    fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
       "    faster_rcnn_75: fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
       "    tp_iou_0_75:    fiftyone.core.fields.IntField\n",
       "    fp_iou_0_75:    fiftyone.core.fields.IntField\n",
       "    fn_iou_0_75:    fiftyone.core.fields.IntField\n",
       "    tp_iou_0_5:     fiftyone.core.fields.IntField\n",
       "    fp_iou_0_5:     fiftyone.core.fields.IntField\n",
       "    fn_iou_0_5:     fiftyone.core.fields.IntField"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every `Sample` now contains new fields `tp_iou_0_75`, `fp_iou_0_75`, and `fn_iou_0_75` corresponding to the total true positive, false positive, and false negative counts in your detections for an IoU of 0.75. This value can be changed using the `save_iou` kwarg in `evaluate_detections(dataset, \"faster_rcnn_75\", \"ground_truth\", save_iou=0.95)`\n",
    "\n",
    "Every `faster_rcnn_75` field in every `Sample` now contains a new `ground_truth_eval` field that contains `true_positives`, `false_positives`, and `false_negatives` ranging from IoUs `0_5`, `0_55`,..., to `0_95`.\n",
    "\n",
    "Every `Detection` in the `faster_rcnn_75` field now also has a `ground_truth_eval` field that contains:\n",
    "* The unique `eval_id` of that detection\n",
    "* The `ious` for every class of that detection with all ground truth detections of that class\n",
    "* The `matches` for 10 IoU values ranging from `0.5` to `0.95` that each contain the `gt_id` and `iou` of the ground truth detection that this predicted detection was matched with according to the pycocotools matching algorithm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Detections\n",
    "Launch the FiftyOne app and easily view ground truth and predicted bounding boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "App launched\n"
     ]
    }
   ],
   "source": [
    "session = fo.launch_app(dataset=dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![launch](images/eval_dets/launch_app.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All fields are shown as togglable bubbles on the left sidebar which can be used to switch between ground truth detections, predictions, and thresholded predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![bubbles](images/eval_dets/togge_bubbles.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Views\n",
    "A `DatasetView` can also be used to search, sort, or slice your dataset for you to look at different views of the samples. \n",
    "\n",
    "Individual samples can be selected and a `DatasetView` can be created to look at just those samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_samples = session.selected\n",
    "session.view = dataset.select(selected_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![selected](images/eval_dets/selected.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reset the session dataset to show the entire dataset again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.dataset = dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tp_iou_0_75` was calculated for each sample during evaluation, we can make a `DatasetView` that sorts by `tp_iou_0_75` to look at the best and worst predictions that the model had based on the number of true positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.view = dataset.view().sort_by(\"tp_iou_0_75\", reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ap_rev](images/eval_dets/ap_rev.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.view = dataset.view().sort_by(\"tp_iou_0_75\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ap](images/eval_dets/ap.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_boxes_view = dataset.filter_detections(\n",
    "    \"faster_rcnn_75\",\n",
    "    F(\"bounding_box\")[2] * F(\"bounding_box\")[3] < 0.02\n",
    ")\n",
    "\n",
    "session.view = small_boxes_view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a view of only samples with the `iscrowd` attribute on a detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "crowded_images_view = dataset.match(\n",
    "    F(\"ground_truth.detections\").filter(F(\"attributes.iscrowd.value\") == 1).length() > 0\n",
    ")\n",
    "\n",
    "session.view = crowded_images_view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort the view of crowded images by false positive count in decreasing order to see samples that have a lot of false predictions but include an `iscrowd` ground truth object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_crowded_images_view = crowded_view.sort_by(\n",
    "    \"fp_iou_0_75\", reverse=True\n",
    ")\n",
    "\n",
    "session.view = sorted_crowded_images_view"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fo",
   "language": "python",
   "name": "fo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
