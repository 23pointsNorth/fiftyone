{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Evaluate Detection Model with FiftyOne\n",
    "\n",
    "This walkthrough demonstrates how use FiftyOne to perform hands-on evaluation of your detection model.\n",
    "\n",
    "It covers the following concepts:\n",
    "* Loading a dataset with detections\n",
    "* Adding detection predictions\n",
    "* Sample-wise MSCOCO evaluation\n",
    "* Sorting and searching samples by model performance\n",
    "* Visualizing true-positives and false-positives\n",
    "* Querying your dataset for a custom insight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "Install `torch` and `torchvision`, if necessary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify as necessary (e.g., GPU install). See https://pytorch.org for options\n",
    "!pip install torch\n",
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the FiftyOne zoo and download the MSCOCO validation split to `~/fiftyone/coco-2017/validation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "import torch, torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = foz.load_zoo_dataset(\"coco-2017\", \"validation\")\n",
    "dataset.persistent=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize Faster-RCNN and download pretrained weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the model on gpu if it is available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Predictions\n",
    "Run Faster-RCNN on every sample in the validation dataset and add detections to our FiftyOne dataset.\n",
    "Predictions are added to each sample in a new field we will call `faster_rcnn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETA is installed with FiftyOne\n",
    "# etai provides functionality to read images into memory\n",
    "import fiftyone.core.utils as fou\n",
    "import eta.core.image as etai\n",
    "import json\n",
    "from torchvision.transforms import functional as TF\n",
    "\n",
    "labels_path = \"/home/erich/fiftyone/coco-2017/validation/labels.json\"\n",
    "with open(labels_path, \"r\") as labels_file:\n",
    "    classes = json.load(labels_file)[\"classes\"]\n",
    "\n",
    "# Add predictions\n",
    "with fou.ProgressBar() as pb:\n",
    "    for sample in pb(dataset):\n",
    "        image = etai.read(sample.filepath)\n",
    "        image = TF.to_tensor(image).to(device)\n",
    "        c,h,w = image.shape\n",
    "\n",
    "        preds = model([image])[0]\n",
    "\n",
    "        labels = preds[\"labels\"].cpu().detach().numpy()\n",
    "        scores = preds[\"scores\"].cpu().detach().numpy()\n",
    "        boxes = preds[\"boxes\"].cpu().detach().numpy()\n",
    "\n",
    "        detections = []\n",
    "        for label, score, box in zip(labels, scores, boxes):\n",
    "            # Compute relative bounding box coordinates\n",
    "            x1, y1, x2, y2 = box\n",
    "            rel_box = [x1/w, y1/h, (x2-x1)/w, (y2-y1)/h]\n",
    "\n",
    "            detections.append(fo.Detection(\n",
    "                label=classes[label],\n",
    "                bounding_box=rel_box,\n",
    "                confidence=score\n",
    "            ))\n",
    "\n",
    "        sample[\"faster_rcnn\"] = fo.Detections(\n",
    "            detections=detections\n",
    "        )\n",
    "        sample.save()\n",
    "\n",
    "print(\"Finished adding predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Detections\n",
    "Use MSCOCO detection evaluation provided within FiftyOne to threshold detections and compute AP for each sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Threshold all detections to remove any detections lower than 0.5 confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "from fiftyone import ViewField as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faster_rcnn_75 = dataset.filter_detections(\"faster_rcnn\", F(\"confidence\")>0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.clone_field(\"faster_rcnn\", \"faster_rcnn_75\", samples=faster_rcnn_75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Match detections to ground truth and compute true and false positives according to MSCOCO evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone.utils.cocoeval as fouc\n",
    "\n",
    "fouc.evaluate_detections(dataset, \"faster_rcnn_75\", \"ground_truth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every `Sample` now contains new fields `tp_iou_0_75`, `fp_iou_0_75`, and `fn_iou_0_75` corresponding to the total true positive, false positive, and false negative counts in your detections for an IoU of 0.75. This value can be changed using the `save_iou` kwarg in `evaluate_detections(dataset, \"faster_rcnn_75\", \"ground_truth\", save_iou=0.95)`\n",
    "\n",
    "Every `faster_rcnn_75` field in every `Sample` now contains a new `ground_truth_eval` field that contains `true_positives`, `false_positives`, and `false_negatives` ranging from IoUs `0_5`, `0_55`,..., to `0_95`.\n",
    "\n",
    "Every `Detection` in the `faster_rcnn_75` field now also has a `ground_truth_eval` field that contains:\n",
    "* The unique `eval_id` of that detection\n",
    "* The `ious` for every class of that detection with all ground truth detections of that class\n",
    "* The `matches` for 10 IoU values ranging from `0.5` to `0.95` that each contain the `gt_id` and `iou` of the ground truth detection that this predicted detection was matched with according to the pycocotools matching algorithm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Detections\n",
    "Launch the FiftyOne app and easily view ground truth and predicted bounding boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = fo.launch_app(dataset=dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![launch](images/eval_dets/launch_app.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All fields are shown as togglable bubbles on the left sidebar which can be used to switch between ground truth detections, predictions, and thresholded predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![bubbles](images/eval_dets/togge_bubbles.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Views\n",
    "A `DatasetView` can also be used to search, sort, or slice your dataset for you to look at different views of the samples. \n",
    "\n",
    "Individual samples can be selected and a `DatasetView` can be created to look at just those samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_samples = session.selected\n",
    "session.view = dataset.select(selected_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![selected](images/eval_dets/selected.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reset the session dataset to show the entire dataset again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.dataset = dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tp_iou_0_75` was calculated for each sample during evaluation, we can make a `DatasetView` that sorts by `tp_iou_0_75` to look at the best and worst predictions that the model had based on the number of true positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.view = dataset.view().sort_by(\"tp_iou_0_75\", reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ap_rev](images/eval_dets/ap_rev.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.view = dataset.view().sort_by(\"tp_iou_0_75\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ap](images/eval_dets/ap.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_boxes_view = dataset.filter_detections(\n",
    "    \"faster_rcnn_75\",\n",
    "    F(\"bounding_box\")[2] * F(\"bounding_box\")[3] < 0.02\n",
    ")\n",
    "\n",
    "session.view = small_boxes_view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a view of only samples with the `iscrowd` attribute on a detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crowded_images_view = dataset.match(\n",
    "    F(\"ground_truth.detections\").filter(F(\"attributes.iscrowd.value\") == 1).length() > 0\n",
    ")\n",
    "\n",
    "session.view = crowded_images_view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort the view of crowded images by false positive count in decreasing order to see samples that have a lot of false predictions but include an `iscrowd` ground truth object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_crowded_images_view = crowded_view.sort_by(\n",
    "    \"fp_iou_0_75\", reverse=True\n",
    ")\n",
    "\n",
    "session.view = sorted_crowded_images_view"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fo",
   "language": "python",
   "name": "fo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
