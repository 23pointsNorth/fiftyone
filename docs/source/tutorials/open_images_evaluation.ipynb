{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Analysis on Open Images Evaluation Results\n",
    "\n",
    "This tutorial demonstrates per-image evaluation of [the Open Images dataset](https://storage.googleapis.com/openimages/web/index.html)\n",
    "that generates:\n",
    "- true positives\n",
    "- false positives\n",
    "- per-class AP\n",
    "- mAP\n",
    "\n",
    "and adds this information to each [Sample](https://voxel51.com/docs/fiftyone/api/fiftyone.core.sample.html#fiftyone.core.sample.Sample)\n",
    "in [Dataset](https://voxel51.com/docs/fiftyone/api/fiftyone.core.dataset.html#fiftyone.core.dataset.Dataset).\n",
    "\n",
    "The steps are broken down as:\n",
    "- [#2.-Download-the-data-and-ground-truth-labels](#2.-Download-the-data-and-ground-truth-labels)\n",
    "\n",
    "If you already have the data downloaded you may skip step 2.\n",
    "\n",
    "If you have your own model you can skip step 3.\n",
    "\n",
    "This tutorial evaluates a model on [Open Images V4](https://storage.googleapis.com/openimages/web/download_v4.html)\n",
    "however this code supports later versions of Open Images as well. If using a newer version just make sure to\n",
    "use the appropriate hierarchy file and class label map."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "This notebook contains bash commands. To run it as a notebook, you must install the [Jupyter bash kernel](https://github.com/takluyver/bash_kernel) via the command below.\n",
    "\n",
    "Alternatively, you can just copy + paste the code blocks into your shell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install bash_kernel\n",
    "python -m bash_kernel.install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This workflow requires a few required python packages.\n",
    "\n",
    "Install the appropriate version of `tensorflow` depending on whether or not you\n",
    "have a GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow\n",
    "# pip install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install other requirements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install Pillow tensorflow-hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download the data and ground-truth labels\n",
    "\n",
    "All of the data can be found on the\n",
    "[official Open Images website](https://storage.googleapis.com/openimages/web/download_v4.html).\n",
    "\n",
    "If you are using Open Images V4 you can use the following commands to download\n",
    "all the necessary files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the data\n",
    "\n",
    "**WARNING** This is 36GB of data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws s3 --no-sign-request sync s3://open-images-dataset/test [target_dir/test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the labels and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wget https://storage.googleapis.com/openimages/2018_04/test/test-annotations-bbox.csv\n",
    "wget https://storage.googleapis.com/openimages/2018_04/test/test-annotations-human-imagelabels-boxable.csv\n",
    "wget https://storage.googleapis.com/openimages/2018_04/class-descriptions-boxable.csv\n",
    "wget https://storage.googleapis.com/openimages/2018_04/bbox_labels_600_hierarchy.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generating predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd PATH/TO/open_images_error_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_DIR=\"/PATH/TO/IMAGES\"\n",
    "OUTPUT_DIR=\"/PATH/TO/PREDICTIONS\"\n",
    "\n",
    "MODEL_HANDLE=\"https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1\"\n",
    "# MODEL_HANDLE=\"https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1\"\n",
    "\n",
    "python scripts/inference.py \\\n",
    "    --output_dir ${OUTPUT_DIR} \\\n",
    "    --output_format tf_object_detection_api \\\n",
    "    ${IMAGES_DIR} ${MODEL_HANDLE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualizing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing FiftyOne\n",
    "\n",
    "We are going to use the [fiftyone](https://github.com/voxel51/fiftyone) package\n",
    "for visualizing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install fiftyone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data into FiftyOne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME=\"open-images-v4-test\"\n",
    "IMAGES_DIR=\"/PATH/TO/IMAGES\"\n",
    "BOUNDING_BOXES_EXPANDED=\"/PATH/TO/test-annotations-bbox_expanded.csv\"\n",
    "IMAGE_LABELS_EXPANDED=\"/PATH/TO/test-annotations-human-imagelabels-boxable_expanded.csv\"\n",
    "PREDICTIONS_PATH=\"/PATH/TO/PREDICTIONS.csv\"\n",
    "CLASS_DESCRIPTIONS=\"/PATH/TO/class-descriptions-boxable.csv\"\n",
    "\n",
    "# @todo(Tyler)\n",
    "DATASET_NAME=\"open-images-v4-test\"\n",
    "IMAGES_DIR=\"~/data/open-images-dataset/TESTING/test_images\"\n",
    "BOUNDING_BOXES_EXPANDED=\"~/data/open-images-dataset/TESTING/test-annotations-bbox_expanded.csv\"\n",
    "IMAGE_LABELS_EXPANDED=\"~/data/open-images-dataset/TESTING/test-annotations-human-imagelabels-boxable_expanded.csv\"\n",
    "PREDICTIONS_PATH=\"~/data/open-images-dataset/TESTING/faster_rcnn_preds_3081.csv\"\n",
    "#PREDICTIONS_PATH=\"~/data/open-images-dataset/TESTING/faster_rcnn_preds_74061.csv\"\n",
    "CLASS_DESCRIPTIONS=\"~/data/open-images-dataset/TESTING/class-descriptions-boxable.csv\"\n",
    "\n",
    "python scripts/load_data.py \\\n",
    "    --bounding_boxes_path ${BOUNDING_BOXES_EXPANDED} \\\n",
    "    --image_labels_path ${IMAGE_LABELS_EXPANDED} \\\n",
    "    --predictions_path ${PREDICTIONS_PATH} \\\n",
    "    --prediction_field_name \"faster_rcnn\" \\\n",
    "    --class_descriptions_path ${CLASS_DESCRIPTIONS} \\\n",
    "    --load_images_with_preds \\\n",
    "    --max_num_images 1000 \\\n",
    "    ${DATASET_NAME} ${IMAGES_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (optional) Visualizing the data\n",
    "\n",
    "We can optionally visualize the data before evaluating. Open up a `python` or\n",
    "`ipython` terminal and run the following:\n",
    "\n",
    "```python\n",
    "import fiftyone as fo\n",
    "from fiftyone import ViewField as F\n",
    "\n",
    "dataset = fo.load_dataset(\"open-images-v4-test\")\n",
    "\n",
    "session = fo.launch_app(dataset=dataset)\n",
    "\n",
    "# Filter the visible detections by confidence\n",
    "session.view = dataset.filter_detections(\"faster_rcnn\", F(\"confidence\") > 0.4)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preparing the ground-truth for evaluation\n",
    "\n",
    "Open Images requires \"expanding the hierarchy\" if the ground-truth labels, for\n",
    "evaluation. The labels you downloaded only contain leaf node labels, so for\n",
    "example, for a bounding box labeled `Jaguar`, the hierarchy expansion would add\n",
    "duplicate boxes with labels `Carnivore`, `Mammal` and `Animal`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing TF Object Detection API\n",
    "\n",
    "The first step is to install the Tensorflow Object Detection API. Instructions\n",
    "on how to do so can be found\n",
    "[here](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create expanded hierarchy ground-truth labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd PATH/TO/models/research/object_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS_DIR=PATH/TO/LABELS\n",
    "\n",
    "HIERARCHY_FILE=${LABELS_DIR}/bbox_labels_600_hierarchy.json\n",
    "BOUNDING_BOXES=${LABELS_DIR}/test-annotations-bbox\n",
    "IMAGE_LABELS=${LABELS_DIR}/test-annotations-human-imagelabels-boxable\n",
    "\n",
    "python dataset_tools/oid_hierarchical_labels_expansion.py \\\n",
    "    --json_hierarchy_file=${HIERARCHY_FILE} \\\n",
    "    --input_annotations=${BOUNDING_BOXES}.csv \\\n",
    "    --output_annotations=${BOUNDING_BOXES}_expanded.csv \\\n",
    "    --annotation_type=1\n",
    "\n",
    "python dataset_tools/oid_hierarchical_labels_expansion.py \\\n",
    "    --json_hierarchy_file=${HIERARCHY_FILE} \\\n",
    "    --input_annotations=${IMAGE_LABELS}.csv \\\n",
    "    --output_annotations=${IMAGE_LABELS}_expanded.csv \\\n",
    "    --annotation_type=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now have two new files in `LABELS_DIR`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test-annotations-bbox_expanded.csv\n",
    "test-annotations-human-imagelabels-boxable_expanded.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluating on a per-image granularity\n",
    "\n",
    "### Running evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export TF_MODELS_RESEARCH=\"/Users/tylerganter/data/open-images-dataset\"\n",
    "CLASS_LABEL_MAP=${TF_MODELS_RESEARCH}/object_detection/data/oid_v4_label_map.pbtxt\n",
    "\n",
    "python scripts/evaluate_model.py \\\n",
    "    --prediction_field_name \"faster_rcnn\" \\\n",
    "    --iou_threshold 0.5 \\\n",
    "    ${DATASET_NAME} ${CLASS_LABEL_MAP}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Error analysis\n",
    "\n",
    "We can now visualize\n",
    "\n",
    "```python\n",
    "import fiftyone as fo\n",
    "from fiftyone import ViewField as F\n",
    "\n",
    "dataset = fo.load_dataset(\"open-images-v4-test\")\n",
    "\n",
    "session = fo.launch_app(dataset=dataset)\n",
    "\n",
    "# Filter the visible detections by confidence\n",
    "session.view = (\n",
    "    dataset\n",
    "    .filter_detections(\"faster_rcnn_TP\", F(\"confidence\") > 0.4)\n",
    "    .filter_detections(\"faster_rcnn_FP\", F(\"confidence\") > 0.4)\n",
    ")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
