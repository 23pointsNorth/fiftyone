{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Analysis on Open Images Evaluation Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install requirements\n",
    "\n",
    "This workflow requires a few required python packages.\n",
    "\n",
    "Install the appropriate version of `tensorflow` depending on whether or not you\n",
    "have a GPU:\n",
    "\n",
    "```bash\n",
    "pip install tensorflow\n",
    "# OR\n",
    "pip install tensorflow-gpu\n",
    "```\n",
    "\n",
    "Install other requirements:\n",
    "\n",
    "```bash\n",
    "pip install Pillow tensorflow-hub\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download the data and ground-truth labels\n",
    "\n",
    "All of the data can be found on the\n",
    "[official Open Images website](https://storage.googleapis.com/openimages/web/download_v4.html).\n",
    "\n",
    "If you are using Open Images V4 you can use the following commands to download\n",
    "all the necessary files.\n",
    "\n",
    "### Download the data\n",
    "\n",
    "**WARNING** This is 36GB of data!\n",
    "\n",
    "```bash\n",
    "aws s3 --no-sign-request sync s3://open-images-dataset/test [target_dir/test]\n",
    "```\n",
    "\n",
    "### Downloading the labels and metadata\n",
    "\n",
    "```bash\n",
    "wget https://storage.googleapis.com/openimages/2018_04/test/test-annotations-bbox.csv\n",
    "wget https://storage.googleapis.com/openimages/2018_04/test/test-annotations-human-imagelabels-boxable.csv\n",
    "wget https://storage.googleapis.com/openimages/2018_04/class-descriptions-boxable.csv\n",
    "wget https://storage.googleapis.com/openimages/2018_04/bbox_labels_600_hierarchy.json\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preparing the ground-truth for evaluation\n",
    "\n",
    "Open Images requires \"expanding the hierarchy\" if the ground-truth labels, for\n",
    "evaluation. The labels you downloaded only contain leaf node labels, so for\n",
    "example, for a bounding box labeled `Jaguar`, the hierarchy expansion would add\n",
    "duplicate boxes with labels `Carnivore`, `Mammal` and `Animal`.\n",
    "\n",
    "### Installing TF Object Detection API\n",
    "\n",
    "The first step is to install the Tensorflow Object Detection API. Instructions\n",
    "on how to do so can be found\n",
    "[here](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2.md).\n",
    "\n",
    "### Create expanded hierarchy ground-truth labels\n",
    "\n",
    "```bash\n",
    "cd PATH/TO/models/research/object_detection\n",
    "```\n",
    "\n",
    "```bash\n",
    "LABELS_DIR=PATH/TO/LABELS\n",
    "\n",
    "HIERARCHY_FILE=${LABELS_DIR}/bbox_labels_600_hierarchy.json\n",
    "BOUNDING_BOXES=${LABELS_DIR}/test-annotations-bbox\n",
    "IMAGE_LABELS=${LABELS_DIR}/test-annotations-human-imagelabels-boxable\n",
    "\n",
    "python dataset_tools/oid_hierarchical_labels_expansion.py \\\n",
    "    --json_hierarchy_file=${HIERARCHY_FILE} \\\n",
    "    --input_annotations=${BOUNDING_BOXES}.csv \\\n",
    "    --output_annotations=${BOUNDING_BOXES}_expanded.csv \\\n",
    "    --annotation_type=1\n",
    "\n",
    "python dataset_tools/oid_hierarchical_labels_expansion.py \\\n",
    "    --json_hierarchy_file=${HIERARCHY_FILE} \\\n",
    "    --input_annotations=${IMAGE_LABELS}.csv \\\n",
    "    --output_annotations=${IMAGE_LABELS}_expanded.csv \\\n",
    "    --annotation_type=2\n",
    "```\n",
    "\n",
    "You should now have two new files in `LABELS_DIR`:\n",
    "\n",
    "```bash\n",
    "test-annotations-bbox_expanded.csv\n",
    "test-annotations-human-imagelabels-boxable_expanded.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generating predictions\n",
    "\n",
    "```bash\n",
    "cd PATH/TO/open_images_error_analysis\n",
    "```\n",
    "\n",
    "```bash\n",
    "IMAGES_DIR=\"/PATH/TO/IMAGES\"\n",
    "OUTPUT_DIR=\"/PATH/TO/PREDICTIONS\"\n",
    "\n",
    "MODEL_HANDLE=\"https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1\"\n",
    "# MODEL_HANDLE=\"https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1\"\n",
    "\n",
    "python scripts/inference.py \\\n",
    "    --output_dir ${OUTPUT_DIR} \\\n",
    "    --output_format tf_object_detection_api \\\n",
    "    ${IMAGES_DIR} ${MODEL_HANDLE}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualizing the data\n",
    "\n",
    "### Installing FiftyOne\n",
    "\n",
    "We are going to use the [fiftyone](https://github.com/voxel51/fiftyone) package\n",
    "for visualizing the data.\n",
    "\n",
    "```bash\n",
    "pip install fiftyone\n",
    "```\n",
    "\n",
    "### Loading the data into FiftyOne\n",
    "\n",
    "```bash\n",
    "DATASET_NAME=\"open-images-v4-test\"\n",
    "IMAGES_DIR=\"/PATH/TO/IMAGES\"\n",
    "BOUNDING_BOXES_EXPANDED=\"/PATH/TO/test-annotations-bbox_expanded.csv\"\n",
    "IMAGE_LABELS_EXPANDED=\"/PATH/TO/test-annotations-human-imagelabels-boxable_expanded.csv\"\n",
    "PREDICTIONS_PATH=\"/PATH/TO/PREDICTIONS.csv\"\n",
    "CLASS_DESCRIPTIONS=\"/PATH/TO/class-descriptions-boxable.csv\"\n",
    "\n",
    "# @todo(Tyler)\n",
    "DATASET_NAME=\"open-images-v4-test\"\n",
    "IMAGES_DIR=\"~/data/open-images-dataset/TESTING/test_images\"\n",
    "BOUNDING_BOXES_EXPANDED=\"~/data/open-images-dataset/TESTING/test-annotations-bbox_expanded.csv\"\n",
    "IMAGE_LABELS_EXPANDED=\"~/data/open-images-dataset/TESTING/test-annotations-human-imagelabels-boxable_expanded.csv\"\n",
    "PREDICTIONS_PATH=\"~/data/open-images-dataset/TESTING/faster_rcnn_preds_3081.csv\"\n",
    "#PREDICTIONS_PATH=\"~/data/open-images-dataset/TESTING/faster_rcnn_preds_74061.csv\"\n",
    "CLASS_DESCRIPTIONS=\"~/data/open-images-dataset/TESTING/class-descriptions-boxable.csv\"\n",
    "\n",
    "python scripts/load_data.py \\\n",
    "    --bounding_boxes_path ${BOUNDING_BOXES_EXPANDED} \\\n",
    "    --image_labels_path ${IMAGE_LABELS_EXPANDED} \\\n",
    "    --predictions_path ${PREDICTIONS_PATH} \\\n",
    "    --prediction_field_name \"faster_rcnn\" \\\n",
    "    --class_descriptions_path ${CLASS_DESCRIPTIONS} \\\n",
    "    --load_images_with_preds \\\n",
    "    --max_num_images 1000 \\\n",
    "    ${DATASET_NAME} ${IMAGES_DIR}\n",
    "```\n",
    "\n",
    "### (optional) Visualizing the data\n",
    "\n",
    "We can optionally visualize the data before evaluating. Open up a `python` or\n",
    "`ipython` terminal and run the following:\n",
    "\n",
    "```python\n",
    "import fiftyone as fo\n",
    "from fiftyone import ViewField as F\n",
    "\n",
    "dataset = fo.load_dataset(\"open-images-v4-test\")\n",
    "\n",
    "session = fo.launch_app(dataset=dataset)\n",
    "\n",
    "# Filter the visible detections by confidence\n",
    "session.view = dataset.filter_detections(\"faster_rcnn\", F(\"confidence\") > 0.4)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluating on a per-image granularity\n",
    "\n",
    "### Running evaluation\n",
    "\n",
    "```bash\n",
    "export TF_MODELS_RESEARCH=\"/Users/tylerganter/data/open-images-dataset\"\n",
    "CLASS_LABEL_MAP=${TF_MODELS_RESEARCH}/object_detection/data/oid_v4_label_map.pbtxt\n",
    "\n",
    "python scripts/evaluate_model.py \\\n",
    "    --prediction_field_name \"faster_rcnn\" \\\n",
    "    --iou_threshold 0.5 \\\n",
    "    ${DATASET_NAME} ${CLASS_LABEL_MAP}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Error analysis\n",
    "\n",
    "We can now visualize\n",
    "\n",
    "```python\n",
    "import fiftyone as fo\n",
    "from fiftyone import ViewField as F\n",
    "\n",
    "dataset = fo.load_dataset(\"open-images-v4-test\")\n",
    "\n",
    "session = fo.launch_app(dataset=dataset)\n",
    "\n",
    "# Filter the visible detections by confidence\n",
    "session.view = (\n",
    "    dataset\n",
    "    .filter_detections(\"faster_rcnn_TP\", F(\"confidence\") > 0.4)\n",
    "    .filter_detections(\"faster_rcnn_FP\", F(\"confidence\") > 0.4)\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fiftyone",
   "language": "python",
   "name": "fiftyone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
