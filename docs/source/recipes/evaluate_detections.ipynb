{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Evaluate Detection Model with FiftyOne\n",
    "\n",
    "This walkthrough demonstrates how use FiftyOne to perform hands-on evaluation of your detection model.\n",
    "\n",
    "It covers the following concepts:\n",
    "* Loading a dataset with detections\n",
    "* Adding detection predictions\n",
    "* Sample-wise MSCOCO evaluation\n",
    "* Sorting and searching samples by model performance\n",
    "* Visualizing true-positives and false-positives\n",
    "* Querying your dataset for a custom insight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "Install `torch` and `torchvision`, if necessary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify as necessary (e.g., GPU install). See https://pytorch.org for options\n",
    "!pip install torch\n",
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the FiftyOne zoo and download the MSCOCO validation split to `~/fiftyone/coco-2017/validation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone.zoo as foz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = foz.load_zoo_dataset(\"coco-2017\", \"validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize Faster-RCNN and download pretrained weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the model on gpu if it is available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Predictions\n",
    "Run Faster-RCNN on every sample in the validation dataset and add detections to our FiftyOne dataset.\n",
    "Predictions are added to each sample in a new field we will call `faster_rcnn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished adding predictions\n"
     ]
    }
   ],
   "source": [
    "# ETA is installed with FiftyOne\n",
    "# etai provides functionality to read images into memory\n",
    "import eta.core.image as etai\n",
    "from torchvision.transforms import functional as F\n",
    "\n",
    "\n",
    "# Add predictions\n",
    "for sample in dataset:\n",
    "    image = etai.read(sample.filepath)\n",
    "    image = F.to_tensor(image).to(device)\n",
    "    \n",
    "    preds = model([image])[0]\n",
    "    \n",
    "    labels = preds[\"labels\"].cpu().detach().numpy()\n",
    "    scores = preds[\"scores\"].cpu().detach().numpy()\n",
    "    boxes = preds[\"boxes\"].cpu().detach().numpy()\n",
    "    \n",
    "    detections = []\n",
    "    for label, score, box in zip(labels, scores, boxes):\n",
    "        # Compute relative bounding box coordinates\n",
    "        x1, y1, x2, y2 = box\n",
    "        rel_box = [x1/w, y1/h, (x2-x1)/w, (y2-y1)/h]\n",
    "        \n",
    "        detections.append(fo.Detection(\n",
    "            label=label,\n",
    "            bounding_box=rel_box,\n",
    "            confidence=score\n",
    "        ))\n",
    "\n",
    "    sample[\"faster_rcnn\"] = fo.Detections(\n",
    "        detections=detections\n",
    "    )\n",
    "    sample.save()\n",
    "\n",
    "print(\"Finished adding predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Detections\n",
    "Use MSCOCO detection evaluation provided within FiftyOne to threshold detections and compute AP for each sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Threshold all detections to remove any detections lower than 0.5 confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in dataset:\n",
    "    sample[\"faster_rcnn_5\"] = sample[\"faster_rcnn\"].filter(0.5)\n",
    "    sample.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Match detections to ground truth and compute AP according to MSCOCO evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.evaluate(\"faster_rcnn_5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation automatically added \n",
    "* `AP`- mAP over IoU values of [0.5,0.55,0.6,...,0.95]\n",
    "* `AP_0_5` - mAP over IoU 0.5\n",
    "* `AP_0_75` - mAP over IoU 0.75\n",
    "* `AP_small` - mAP over objects with small bounding boxes\n",
    "* `AP_medium` - mAP over objects with medium bounding boxes\n",
    "* `AP_large` - mAP over objects with large bounding boxes \n",
    "\n",
    "Implementations can be found in the `pycocotools` repository: https://github.com/cocodataset/cocoapi/blob/master/PythonAPI/pycocotools/cocoeval.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, every detection stores which ground truth boxes they were matched with, if any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(dataset)\n",
    "\n",
    "print(sample[\"faster_rcnn_75\"].detections[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute true and false positives for each sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in dataset:\n",
    "    tp_dets = []\n",
    "    fp_dets = []\n",
    "    matched_gt = []\n",
    "    missed_gt = []\n",
    "                                                                                                                                                                                                            \n",
    "    gt_ids = {x.attributes[\"coco_id\"].value: x for x in sample.ground_truth.detections}\n",
    "    \n",
    "    for det in sample['faster-rcnn_75'].detections:\n",
    "        gtid75 = det.attributes['gtId_75'].value\n",
    "        if gtid75 == 0:\n",
    "            fp_dets.append(det)\n",
    "        else:\n",
    "            tp_dets.append(det)\n",
    "            matched_gt.append(gt_ids[gtid75])\n",
    "            \n",
    "    missed_gt = [x for x in gt_ids.values() if x not in matched_gt]\n",
    "    sample['faster_rcnn_75_tp'] = fol.Detections(detections=tp_dets)\n",
    "    sample['faster_rcnn_75_fp'] = fol.Detections(detections=fp_dets)\n",
    "    sample['faster_rcnn_75_gt_matched'] = fol.Detections(detections=matched_gt)\n",
    "    sample['faster_rcnn_75_gt_missed'] = fol.Detections(detections=missed_gt)\n",
    "    sample.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Detections\n",
    "Launch the FiftyOne app and easily view ground truth and predicted bounding boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "App launched\n"
     ]
    }
   ],
   "source": [
    "session = fo.launch_app(dataset=dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![launch](images/eval_dets/launch_app.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All fields are shown as togglable bubbles on the left sidebar which can be used to switch between viewing true positives, false positives, missed ground truth boxes, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![bubbles](images/eval_dets/togge_bubbles.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Views\n",
    "A `DatasetView` can also be used to search, sort, or splice your dataset for you to look at different views of the samples. \n",
    "\n",
    "Individual samples can be selected and a `DatasetView` can be created to look at just those samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_samples = session.selected\n",
    "session.view = dataset.view().select(selected_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![selected](images/eval_dets/selected.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reset the session dataset to show the entire dataset again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.dataset = dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`AP` was calculated for each sample during evaluation, we can make a `DatasetView` that sorts by `AP` to look at the best and worst predictions that the model had."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.view = dataset.view().sort_by(\"AP\", reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ap_rev](images/eval_dets/ap_rev.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.view = dataset.view().sort_by(\"AP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ap](images/eval_dets/ap.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluation also stored `AP` by bounding box size in the fields named `AP_small`, `AP_medium`, and `AP_large`. This can be used to look at how the model performed on small samples, for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.view = dataset.view().sort_by(\"AP_small\", reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ap_small](images/eval_dets/ap_small.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.view = dataset.view().sort_by(\"AP_small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ap_small_rev](images/eval_dets/ap_small_rev.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, some samples did not contain any small objects. We can define a query using [MongoDB queries]( https://docs.mongodb.com/manual/tutorial/query-documents/) and the `.match()` method of a `DatasetView` in order to find all samples that have an `AP_small` of `0` or `None`. We can then remove them from our view and only look at samples that contain small objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match all samples that where the field `AP_small` equals 0 or None\n",
    "query = {\"$or\" : [{\"AP_small\" : 0}, {\"AP_small\" : None}]}\n",
    "no_small_objs_view = dataset.view().match(query)\n",
    "\n",
    "# Get all ID's of the samples that have no small objects\n",
    "# Then create a new view without those samples\n",
    "no_small_ids = [s.id for s in no_small_objs_view]\n",
    "small_view = dataset.view().exclude(no_small_ids)\n",
    "\n",
    "# Visualize this new view that contains only samples with small objects\n",
    "session.view = small_view.sort_by(\"AP_small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ap_small_only](images/eval_dets/ap_small_only.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
