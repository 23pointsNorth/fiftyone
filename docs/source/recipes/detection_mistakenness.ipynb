{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection Mistakenness with FiftyOne\n",
    "\n",
    "Finding mistakes in your annotations can be extremely tedious. The mistakenness feature of FiftyOne can be used to help you find annotation mistakes. Check out [our classification tutorial](https://voxel51.com/docs/fiftyone/tutorials/label_mistakes.html) to see how FiftyOne can help you find and correct label mistakes in your classification datasets.\n",
    "\n",
    "This recipe is designed to show you how you can use FiftyOne to compute mistakenness on your detection dataset, enabling you to curate higher quality datasets and, ultimately, train better models!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In this recipe, we explore how FiftyOne can be used to help you find mistakes in your detection annotations.\n",
    "\n",
    "Requirements:\n",
    "\n",
    "- A detection model trained on the same label schema as the annotations you want to analyze\n",
    "- A FiftyOne Dataset with your annotations and predictions from the model with logits for each detection\n",
    "\n",
    "\n",
    "We'll cover the following concepts:\n",
    "\n",
    "-   Computing insights into your detection dataset relating to possible mistakes\n",
    "-   Visualizing the mistake in the FiftyOne App\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Mistakenness for detection datasets will add the following fields:\n",
    "\n",
    "Ground truth detection fields:\n",
    "\n",
    "- `mistakenness`: A measure of the correctness of the detection and classification of the object therein\n",
    "- `mistakenness_loc`: Specificaly a measure of the mistakenness of the localization of the bounding box\n",
    "- `possible_mistake`: If the ground truth object was not matched with a prediction, it is flagged as a possible mistake\n",
    "\n",
    "Prediction field:\n",
    "\n",
    "- `possible_mistake`: If the prediction was confident but not matched with a ground truth object, it is flagged as a possible mistake\n",
    "\n",
    "\n",
    "Sample level fields:\n",
    "\n",
    "- `mistakenness`: An average of the `mistakenness` of all detections (larger values are more likely to be mistakes)\n",
    "- `possible_mistake`: The number of possible mistakes across all detections in the sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Your Dataset should have two `Detections` fields, one with your ground truth annotations and one with your model predictions.\n",
    "\n",
    "In this example, I used the `coco-2017-validation` dataset from the [FiftyOne zoo](https://voxel51.com/docs/fiftyone/user_guide/dataset_creation/zoo.html) and added predictions from the [PyTorch implementation of Faster-RCNN](https://github.com/pytorch/vision/blob/master/torchvision/models/detection/faster_rcnn.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:           coco-2017-validation\n",
      "Media type:     image\n",
      "Num samples:    1002\n",
      "Persistent:     True\n",
      "Info:           {'classes': ['0', 'person', 'bicycle', ...]}\n",
      "Tags:           ['validation']\n",
      "Sample fields:\n",
      "    filepath:     fiftyone.core.fields.StringField\n",
      "    tags:         fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
      "    metadata:     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.Metadata)\n",
      "    ground_truth: fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "    predictions:  fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n"
     ]
    }
   ],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "\n",
    "dataset = foz.load_zoo_dataset(\"coco-2017\", split=\"validation\")\n",
    "\n",
    "add_custom_predictions(dataset)\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Detection: {\n",
      "    'id': '5fbd91988d2308dc08d1e091',\n",
      "    '_id': '5fbd91988d2308dc08d1e091',\n",
      "    'attributes': BaseDict({}),\n",
      "    'label': 'chair',\n",
      "    'bounding_box': BaseList([\n",
      "        0.4544248104095459,\n",
      "        0.510538163879108,\n",
      "        0.10179729461669922,\n",
      "        0.2363765519549589,\n",
      "    ]),\n",
      "    'mask': None,\n",
      "    'confidence': 0.9961196184158325,\n",
      "    'index': None,\n",
      "    '_cls': 'Detection',\n",
      "    'logits': BaseList([\n",
      "        9.405427932739258,\n",
      "        6.29296875,\n",
      "        2.7285072803497314,\n",
      "        0.41016122698783875,\n",
      "        1.419637680053711,\n",
      "        -1.2565374374389648,\n",
      "        -0.6636660695075989,\n",
      "        -2.6886038780212402,\n",
      "        -0.48208746314048767,\n",
      "        1.0514572858810425,\n",
      "        -1.1872789859771729,\n",
      "        -2.45004940032959,\n",
      "        -2.424051284790039,\n",
      "        -4.479976177215576,\n",
      "        -1.658575177192688,\n",
      "        6.200488567352295,\n",
      "        -1.1229450702667236,\n",
      "        -1.4458647966384888,\n",
      "        1.2875698804855347,\n",
      "        0.9066644906997681,\n",
      "        -0.24453511834144592,\n",
      "        -0.5341638326644897,\n",
      "        -0.5780832767486572,\n",
      "        -3.8168420791625977,\n",
      "        -2.4393277168273926,\n",
      "        -1.7479203939437866,\n",
      "        -2.42569637298584,\n",
      "        2.8227875232696533,\n",
      "        3.4634289741516113,\n",
      "        -2.4358460903167725,\n",
      "        -2.383185386657715,\n",
      "        3.2465133666992188,\n",
      "        -0.43927597999572754,\n",
      "        1.0171103477478027,\n",
      "        -2.3703653812408447,\n",
      "        -1.3937132358551025,\n",
      "        -2.8659615516662598,\n",
      "        -1.8849008083343506,\n",
      "        0.5732832551002502,\n",
      "        -1.2414355278015137,\n",
      "        -2.519754648208618,\n",
      "        -2.6924564838409424,\n",
      "        0.5093255043029785,\n",
      "        0.6381282210350037,\n",
      "        0.31547603011131287,\n",
      "        -2.3855655193328857,\n",
      "        3.0848782062530518,\n",
      "        0.4582028090953827,\n",
      "        -0.3872595429420471,\n",
      "        0.15251658856868744,\n",
      "        -0.5324690341949463,\n",
      "        0.4292207658290863,\n",
      "        -0.5816909074783325,\n",
      "        -3.795700788497925,\n",
      "        0.10684294998645782,\n",
      "        -0.6608136892318726,\n",
      "        -3.1287920475006104,\n",
      "        -0.9525023102760315,\n",
      "        -0.9534338116645813,\n",
      "        -1.872353434562683,\n",
      "        -2.0905768871307373,\n",
      "        -1.7905584573745728,\n",
      "        15.888718605041504,\n",
      "        6.575275421142578,\n",
      "        2.0940823554992676,\n",
      "        3.761392116546631,\n",
      "        -2.415929079055786,\n",
      "        9.728534698486328,\n",
      "        -2.442200183868408,\n",
      "        -2.375725746154785,\n",
      "        1.1997876167297363,\n",
      "        -2.4075965881347656,\n",
      "        2.7193431854248047,\n",
      "        1.2548465728759766,\n",
      "        -2.2832231521606445,\n",
      "        -1.565345048904419,\n",
      "        0.08382335305213928,\n",
      "        -1.8068443536758423,\n",
      "        -0.812242329120636,\n",
      "        3.1053946018218994,\n",
      "        -1.5395545959472656,\n",
      "        0.4952964782714844,\n",
      "        2.0353963375091553,\n",
      "        -2.4610908031463623,\n",
      "        0.5420143008232117,\n",
      "        -1.7428443431854248,\n",
      "        2.5418789386749268,\n",
      "        -0.9653403162956238,\n",
      "        0.12461099028587341,\n",
      "        -1.4128222465515137,\n",
      "        -3.2395172119140625,\n",
      "    ]),\n",
      "}>\n"
     ]
    }
   ],
   "source": [
    "print(dataset.first().predictions.detections[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the mistakes\n",
    "\n",
    "Now we can run a method from the FiftyOne Brain that estimates the mistakenness of the\n",
    "ground truth detections for which we generated predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating detections...\n",
      " 100% |██████████████████████████████████████████████████████████████| 1002/1002 [48.0s elapsed, 0s remaining, 23.2 samples/s]      \n",
      "Computing mistakenness...\n",
      "  100% |██████████████████████████████████████████████████████████████| 1002/1002 [50.1s elapsed, 0s remaining, 24.6 samples/s]    \n",
      "  100% |██████████████████████████████████████████████████████████████| 1002/1002 [51.6s elapsed, 0s remaining, 26.0 samples/s]      \n",
      "Mistakenness computation complete\n"
     ]
    }
   ],
   "source": [
    "import fiftyone.brain as fob\n",
    "\n",
    "# Compute mistakenness, use the field names of your dataset in place of \"predictions\" and \"ground_truth\"\n",
    "fob.compute_mistakenness(dataset, \"predictions\", label_field=\"ground_truth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above method added fields to all samples for which we had predictions at both a sample and detection level. Specifically, it added the following.\n",
    "\n",
    "Ground truth detection fields:\n",
    "\n",
    "- `mistakenness`: A measure of the correctness of the detection and classification of the object therein\n",
    "- `mistakenness_loc`: Specificaly a measure of the mistakenness of the localization of the bounding box\n",
    "- `possible_mistake`: If the ground truth object was not matched with a prediction, it is flagged as a possible mistake\n",
    "\n",
    "Prediction field:\n",
    "\n",
    "- `possible_mistake`: If the prediction was confident but not matched with a ground truth object, it is flagged as a possible mistake\n",
    "\n",
    "Sample level fields:\n",
    "\n",
    "- `mistakenness`: An average of the `mistakenness` of all detections (larger values are more likely to be mistakes)\n",
    "- `possible_mistake`: The number of possible mistakes across all detections in the sample\n",
    "\n",
    "We can easily sort by likelihood of mistakenness from code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:        coco-2017-validation\n",
      "Media type:     image\n",
      "Num samples:    1002\n",
      "Tags:           ['validation']\n",
      "Sample fields:\n",
      "    filepath:          fiftyone.core.fields.StringField\n",
      "    tags:              fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
      "    metadata:          fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.Metadata)\n",
      "    ground_truth:      fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "    predictions:       fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "    mistakenness:      fiftyone.core.fields.FloatField\n",
      "    possible_mistakes: fiftyone.core.fields.IntField\n",
      "Pipeline stages:\n",
      "    1. SortBy(field_or_expr='mistakenness', reverse=True)\n"
     ]
    }
   ],
   "source": [
    "# Sort by likelihood of mistake (most likely first)\n",
    "mistake_view = (dataset\n",
    "    .sort_by(\"mistakenness\", reverse=True)\n",
    ")\n",
    "\n",
    "# Print some information about the view\n",
    "print(mistake_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Detection: {\n",
      "    'id': '5fbd91818d2308dc08d0badc',\n",
      "    '_id': '5fbd91818d2308dc08d0badc',\n",
      "    'attributes': BaseDict({\n",
      "        'area': <NumericAttribute: {'value': 2784.7888000000003, '_cls': 'NumericAttribute'}>,\n",
      "        'iscrowd': <NumericAttribute: {'value': 0.0, '_cls': 'NumericAttribute'}>,\n",
      "    }),\n",
      "    'label': 'kite',\n",
      "    'bounding_box': BaseList([\n",
      "        0.43630232558139537,\n",
      "        0.174640625,\n",
      "        0.23800000000000002,\n",
      "        0.114140625,\n",
      "    ]),\n",
      "    'mask': None,\n",
      "    'confidence': None,\n",
      "    'index': None,\n",
      "    '_cls': 'Detection',\n",
      "    'predictions_eval': BaseDict({\n",
      "        'matches': BaseDict({\n",
      "            '0_5': BaseDict({\n",
      "                'pred_id': '5fbd921c8d2308dc08d205d4',\n",
      "                'iou': 0.5872641643442088,\n",
      "            }),\n",
      "        }),\n",
      "    }),\n",
      "    'mistakenness': 0.983423712863277,\n",
      "    'mistakenness_loc': 0.8146814475545225,\n",
      "}>\n"
     ]
    }
   ],
   "source": [
    "# Inspect some samples and detections\n",
    "# This is the first detection of the first sample\n",
    "print(mistake_view.first().ground_truth.detections[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the App to visually inspect the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "App launched\n"
     ]
    }
   ],
   "source": [
    "# Launch the FiftyOne App\n",
    "session = fo.launch_app()\n",
    "\n",
    "# Open your dataset in the App\n",
    "session.dataset = dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dataset](images/det_mistakenness_1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the top 50 samples we processed in rank order by the mistakenness\n",
    "session.view = mistake_view[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![view](images/det_mistakenness_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another useful query is to find all objects that have a high mistakenness, lets say > 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fiftyone import ViewField as F\n",
    "\n",
    "high_mistake_view = dataset.filter_detections(\"ground_truth\", F(\"mistakenness\") > 0.95, only_matches=True)\n",
    "\n",
    "session.view = high_mistake_view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking through the results, we see some annotations that may be incorrect. For example, in the image below the `goat` is labeled as a `sheep`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![sheep](images/det_mistakenness_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a similar workflow to look at objects that may be localized poorly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_view = dataset.filter_detections(\"ground_truth\", F(\"mistakenness_loc\") > 0.95, only_matches=True)\n",
    "\n",
    "session.view = loc_view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the examples that popped up from this query is shown below. It is a wine glass that was incorrectly box during the annotation process where the bottom of the glass was missed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![wine](images/det_mistakenness_4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `possible_mistakes` field can also be useful to sort by to find instances of incorrect annotations or missed objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.view = dataset.sort_by(\"possible_mistakes\", reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example that showed up from this search is shown below. There is a `car` annotation that was not detected by the model and upon closer inspection, it does not appear to actually be a car."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![car](images/det_mistakenness_5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember: Since you are using model predictions to guide the mistakenness process, the better your model, the more accurate the mistakenness suggestions. We used Faster-RCNN in this example which is quite a few years old. Using a newer detector can provide better results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
